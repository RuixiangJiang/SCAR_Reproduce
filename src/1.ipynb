{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T16:05:16.336409Z",
     "start_time": "2025-10-08T16:04:29.662698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!python Feature_Extract.py aes128_table_ecb key_in\n",
    "\n",
    "!python Feature_Extract.py AES_PPRM1 Kin AES_PPRM1\n",
    "!python Feature_Extract.py AES_PPRM3 Kin AES_PPRM3\n",
    "!python Feature_Extract.py AES_TBL Kin AES_TBL\n",
    "!python Feature_Extract.py RSA Kin RSA\n",
    "!python Feature_Extract.py SABER pol_64bit_in SABER\n",
    "!python Feature_Extract.py PRESENT key PRESENT"
   ],
   "id": "20a0d4c2da617730",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ruixiang/PycharmProjects/SCAR/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\r\n",
      "  warnings.warn(\r\n",
      "Loading cached VCD object from: ../data/aes128_table_ecb/aes128_table_ecb_vcd.pkl\r\n",
      "Loading toggle counts from cache: ../data/aes128_table_ecb/aes128_table_ecb_toggle.txt\r\n",
      "Successfully loaded toggle counts from cache.\r\n",
      "[INFO] Features written to ../out/features.csv\r\n",
      "[INFO] Edges written to ../out/edges.csv\r\n",
      "/Users/ruixiang/PycharmProjects/SCAR/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\r\n",
      "  warnings.warn(\r\n",
      "Loading cached VCD object from: ../data/AES_PPRM1/AES_PPRM1_vcd.pkl\r\n",
      "Loading toggle counts from cache: ../data/AES_PPRM1/AES_PPRM1_toggle.txt\r\n",
      "Successfully loaded toggle counts from cache.\r\n",
      "[INFO] Features written to ../test/AES_PPRM1_features.csv\r\n",
      "[INFO] Edges written to ../test/AES_PPRM1_edges.csv\r\n",
      "/Users/ruixiang/PycharmProjects/SCAR/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\r\n",
      "  warnings.warn(\r\n",
      "Loading cached VCD object from: ../data/AES_PPRM3/AES_PPRM3_vcd.pkl\r\n",
      "Loading toggle counts from cache: ../data/AES_PPRM3/AES_PPRM3_toggle.txt\r\n",
      "Successfully loaded toggle counts from cache.\r\n",
      "[INFO] Features written to ../test/AES_PPRM3_features.csv\r\n",
      "[INFO] Edges written to ../test/AES_PPRM3_edges.csv\r\n",
      "/Users/ruixiang/PycharmProjects/SCAR/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\r\n",
      "  warnings.warn(\r\n",
      "Loading cached VCD object from: ../data/AES_TBL/AES_TBL_vcd.pkl\r\n",
      "Loading toggle counts from cache: ../data/AES_TBL/AES_TBL_toggle.txt\r\n",
      "Successfully loaded toggle counts from cache.\r\n",
      "[INFO] Features written to ../test/AES_TBL_features.csv\r\n",
      "[INFO] Edges written to ../test/AES_TBL_edges.csv\r\n",
      "/Users/ruixiang/PycharmProjects/SCAR/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\r\n",
      "  warnings.warn(\r\n",
      "Loading cached VCD object from: ../data/RSA/RSA_vcd.pkl\r\n",
      "Loading toggle counts from cache: ../data/RSA/RSA_toggle.txt\r\n",
      "Successfully loaded toggle counts from cache.\r\n",
      "[INFO] Features written to ../test/RSA_features.csv\r\n",
      "[INFO] Edges written to ../test/RSA_edges.csv\r\n",
      "/Users/ruixiang/PycharmProjects/SCAR/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\r\n",
      "  warnings.warn(\r\n",
      "Loading cached VCD object from: ../data/SABER/SABER_vcd.pkl\r\n",
      "Loading toggle counts from cache: ../data/SABER/SABER_toggle.txt\r\n",
      "Successfully loaded toggle counts from cache.\r\n",
      "[INFO] Features written to ../test/SABER_features.csv\r\n",
      "[INFO] Edges written to ../test/SABER_edges.csv\r\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T16:50:03.920291Z",
     "start_time": "2025-10-08T16:49:51.761849Z"
    }
   },
   "cell_type": "code",
   "source": "!python SCAR_GNN.py",
   "id": "36d97c0413864c34",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ruixiang/PycharmProjects/SCAR/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\r\n",
      "  warnings.warn(\r\n",
      "num_features: 7, num_classes: 2\r\n",
      "feature_names: ['Degree', 'Hamming distance', 'Paths', 'and', 'mux', 'or', 'xor']\r\n",
      "Train label distribution:\r\n",
      "label\r\n",
      "0    66\r\n",
      "1    66\r\n",
      "Name: count, dtype: int64\r\n",
      "\r\n",
      "Test label distribution:\r\n",
      "label\r\n",
      "0    17\r\n",
      "1     6\r\n",
      "Name: count, dtype: int64\r\n",
      "Epoch 1/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 47ms/step - acc: 0.5502 - loss: 6.3575 - precision: 0.6072 - recall: 0.1872 - val_acc: 0.2143 - val_loss: 12.6759 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 2/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5277 - loss: 6.7502 - precision: 0.4062 - recall: 0.1757 - val_acc: 0.2143 - val_loss: 10.6241 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 3/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.3580 - loss: 9.5048 - precision: 0.1971 - recall: 0.0691 - val_acc: 0.2143 - val_loss: 7.2816 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 4/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.4442 - loss: 8.2671 - precision: 0.3009 - recall: 0.1097 - val_acc: 0.4286 - val_loss: 6.5215 - val_precision: 1.0000 - val_recall: 0.2727\r\n",
      "Epoch 5/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5116 - loss: 7.6791 - precision: 0.5629 - recall: 0.1570 - val_acc: 0.4286 - val_loss: 6.3937 - val_precision: 1.0000 - val_recall: 0.2727\r\n",
      "Epoch 6/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5138 - loss: 7.0108 - precision: 0.3858 - recall: 0.1320 - val_acc: 0.4286 - val_loss: 7.4846 - val_precision: 1.0000 - val_recall: 0.2727\r\n",
      "Epoch 7/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.4908 - loss: 7.6626 - precision: 0.3558 - recall: 0.1503 - val_acc: 0.4286 - val_loss: 9.2906 - val_precision: 1.0000 - val_recall: 0.2727\r\n",
      "Epoch 8/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.4885 - loss: 7.3371 - precision: 0.3449 - recall: 0.1060 - val_acc: 0.4286 - val_loss: 9.3059 - val_precision: 1.0000 - val_recall: 0.2727\r\n",
      "Epoch 9/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.5457 - loss: 7.0809 - precision: 0.4917 - recall: 0.0866 - val_acc: 0.4286 - val_loss: 9.3132 - val_precision: 1.0000 - val_recall: 0.2727\r\n",
      "Epoch 10/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.4908 - loss: 7.5269 - precision: 0.3503 - recall: 0.1163 - val_acc: 0.4286 - val_loss: 9.3174 - val_precision: 1.0000 - val_recall: 0.2727\r\n",
      "Epoch 11/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.4340 - loss: 7.3357 - precision: 0.3010 - recall: 0.1307 - val_acc: 0.4286 - val_loss: 9.3367 - val_precision: 1.0000 - val_recall: 0.2727\r\n",
      "Epoch 12/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.4918 - loss: 7.7820 - precision: 0.2626 - recall: 0.0543 - val_acc: 0.2143 - val_loss: 9.3635 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 13/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.4407 - loss: 7.8242 - precision: 0.1871 - recall: 0.0523 - val_acc: 0.2143 - val_loss: 9.4023 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 14/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.4733 - loss: 7.7904 - precision: 0.3315 - recall: 0.1322 - val_acc: 0.2143 - val_loss: 9.4404 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 15/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.5275 - loss: 6.6037 - precision: 0.4243 - recall: 0.1187 - val_acc: 0.2143 - val_loss: 9.5014 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 16/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.4903 - loss: 7.7373 - precision: 0.5063 - recall: 0.0817 - val_acc: 0.2143 - val_loss: 9.5763 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 17/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.3991 - loss: 7.3386 - precision: 0.1924 - recall: 0.0874 - val_acc: 0.2143 - val_loss: 9.7212 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 18/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.4360 - loss: 8.2294 - precision: 0.2457 - recall: 0.0776 - val_acc: 0.2143 - val_loss: 12.6642 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 19/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.4859 - loss: 7.1755 - precision: 0.0901 - recall: 0.0253 - val_acc: 0.2143 - val_loss: 12.6642 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 20/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5625 - loss: 6.2671 - precision: 0.3413 - recall: 0.1240 - val_acc: 0.2143 - val_loss: 12.6642 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 21/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.4740 - loss: 7.3665 - precision: 0.3328 - recall: 0.0781 - val_acc: 0.2143 - val_loss: 12.6642 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 22/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.4919 - loss: 7.4459 - precision: 0.5900 - recall: 0.1553 - val_acc: 0.2143 - val_loss: 12.6642 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 23/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.4454 - loss: 7.9087 - precision: 0.2847 - recall: 0.0815 - val_acc: 0.2143 - val_loss: 12.6642 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 24/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5189 - loss: 6.8449 - precision: 0.3534 - recall: 0.1239 - val_acc: 0.2143 - val_loss: 12.6642 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 25/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5403 - loss: 7.2702 - precision: 0.4141 - recall: 0.1247 - val_acc: 0.2143 - val_loss: 12.6642 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 26/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.4412 - loss: 8.2026 - precision: 0.2246 - recall: 0.0610 - val_acc: 0.2143 - val_loss: 12.6642 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 27/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5259 - loss: 7.0740 - precision: 0.5389 - recall: 0.1478 - val_acc: 0.2143 - val_loss: 12.6642 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 28/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.4544 - loss: 8.1334 - precision: 0.4820 - recall: 0.1341 - val_acc: 0.2143 - val_loss: 12.6642 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 29/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.4972 - loss: 7.4557 - precision: 0.4521 - recall: 0.1369 - val_acc: 0.2143 - val_loss: 12.6642 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 30/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.4807 - loss: 7.4302 - precision: 0.3667 - recall: 0.1241 - val_acc: 0.2143 - val_loss: 12.6642 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 31/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5446 - loss: 6.9099 - precision: 0.4451 - recall: 0.1642 - val_acc: 0.2143 - val_loss: 12.6642 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 32/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5036 - loss: 7.2069 - precision: 0.4496 - recall: 0.1699 - val_acc: 0.2143 - val_loss: 12.6642 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 1/32\r\n",
      "Tensor(\"GatherV2:0\", shape=(None, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(None, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(None, 32), dtype=float32)\r\n",
      "\u001B[1m1/6\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m14s\u001B[0m 3s/step - acc: 0.7000 - loss: 6.2079 - precision_1: 0.7500 - recall_1: 0.8571Tensor(\"gnn_model_1/GatherV2:0\", shape=(None, 32), dtype=float32)\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 57ms/step - acc: 0.5903 - loss: 6.3463 - precision_1: 0.5911 - recall_1: 0.7896 - val_acc: 0.6429 - val_loss: 0.5673 - val_precision_1: 0.8000 - val_recall_1: 0.7273\r\n",
      "Epoch 2/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.4994 - loss: 8.2524 - precision_1: 0.4346 - recall_1: 0.8445 - val_acc: 0.6429 - val_loss: 0.5034 - val_precision_1: 0.8000 - val_recall_1: 0.7273\r\n",
      "Epoch 3/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5284 - loss: 5.7687 - precision_1: 0.5134 - recall_1: 0.7735 - val_acc: 0.6429 - val_loss: 0.4540 - val_precision_1: 0.8000 - val_recall_1: 0.7273\r\n",
      "Epoch 4/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5429 - loss: 4.9841 - precision_1: 0.4898 - recall_1: 0.7573 - val_acc: 0.6429 - val_loss: 0.4100 - val_precision_1: 0.8000 - val_recall_1: 0.7273\r\n",
      "Epoch 5/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5293 - loss: 4.1522 - precision_1: 0.5030 - recall_1: 0.7468 - val_acc: 0.6429 - val_loss: 0.3724 - val_precision_1: 0.8000 - val_recall_1: 0.7273\r\n",
      "Epoch 6/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.5443 - loss: 3.1904 - precision_1: 0.5398 - recall_1: 0.6983 - val_acc: 0.7857 - val_loss: 0.3432 - val_precision_1: 1.0000 - val_recall_1: 0.7273\r\n",
      "Epoch 7/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.6551 - loss: 2.9403 - precision_1: 0.5974 - recall_1: 0.8273 - val_acc: 0.7857 - val_loss: 0.3250 - val_precision_1: 1.0000 - val_recall_1: 0.7273\r\n",
      "Epoch 8/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.7455 - loss: 3.4841 - precision_1: 0.7161 - recall_1: 0.7701 - val_acc: 0.7857 - val_loss: 0.3152 - val_precision_1: 1.0000 - val_recall_1: 0.7273\r\n",
      "Epoch 9/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.7245 - loss: 3.9252 - precision_1: 0.6656 - recall_1: 0.7785 - val_acc: 0.7857 - val_loss: 0.3124 - val_precision_1: 1.0000 - val_recall_1: 0.7273\r\n",
      "Epoch 10/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.6949 - loss: 2.3384 - precision_1: 0.6631 - recall_1: 0.6953 - val_acc: 0.7857 - val_loss: 0.3138 - val_precision_1: 1.0000 - val_recall_1: 0.7273\r\n",
      "Epoch 11/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.7318 - loss: 1.5589 - precision_1: 0.6825 - recall_1: 0.7392 - val_acc: 0.7857 - val_loss: 0.3237 - val_precision_1: 1.0000 - val_recall_1: 0.7273\r\n",
      "Epoch 12/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.7919 - loss: 0.9896 - precision_1: 0.7802 - recall_1: 0.7971 - val_acc: 0.7857 - val_loss: 0.3445 - val_precision_1: 1.0000 - val_recall_1: 0.7273\r\n",
      "Epoch 13/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.7332 - loss: 1.2410 - precision_1: 0.7007 - recall_1: 0.6916 - val_acc: 0.7857 - val_loss: 0.3960 - val_precision_1: 1.0000 - val_recall_1: 0.7273\r\n",
      "Epoch 14/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.7129 - loss: 0.8455 - precision_1: 0.6861 - recall_1: 0.6819 - val_acc: 0.7857 - val_loss: 0.5038 - val_precision_1: 1.0000 - val_recall_1: 0.7273\r\n",
      "Epoch 15/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.7114 - loss: 0.6044 - precision_1: 0.7250 - recall_1: 0.5880 - val_acc: 0.2857 - val_loss: 0.7068 - val_precision_1: 1.0000 - val_recall_1: 0.0909\r\n",
      "Epoch 16/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5114 - loss: 0.5835 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_acc: 0.2143 - val_loss: 0.8468 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\r\n",
      "Epoch 17/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5372 - loss: 0.5962 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_acc: 0.2143 - val_loss: 0.8173 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\r\n",
      "Epoch 18/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5581 - loss: 0.5544 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_acc: 0.2143 - val_loss: 0.7087 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\r\n",
      "Epoch 19/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5048 - loss: 0.5829 - precision_1: 0.2755 - recall_1: 0.0603 - val_acc: 0.5000 - val_loss: 0.6272 - val_precision_1: 1.0000 - val_recall_1: 0.3636\r\n",
      "Epoch 20/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.6820 - loss: 0.5666 - precision_1: 0.7538 - recall_1: 0.5047 - val_acc: 0.6429 - val_loss: 0.6145 - val_precision_1: 1.0000 - val_recall_1: 0.5455\r\n",
      "Epoch 21/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.6937 - loss: 0.5613 - precision_1: 0.7787 - recall_1: 0.4589 - val_acc: 0.3571 - val_loss: 0.6470 - val_precision_1: 1.0000 - val_recall_1: 0.1818\r\n",
      "Epoch 22/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.5530 - loss: 0.5323 - precision_1: 0.2891 - recall_1: 0.0385 - val_acc: 0.2143 - val_loss: 0.6612 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\r\n",
      "Epoch 23/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5352 - loss: 0.5153 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_acc: 0.2143 - val_loss: 0.6502 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\r\n",
      "Epoch 24/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.4950 - loss: 0.5408 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_acc: 0.2857 - val_loss: 0.6391 - val_precision_1: 1.0000 - val_recall_1: 0.0909\r\n",
      "Epoch 25/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.4750 - loss: 0.5675 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_acc: 0.2143 - val_loss: 0.6375 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\r\n",
      "Epoch 26/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.5347 - loss: 0.5392 - precision_1: 0.2000 - recall_1: 0.0273 - val_acc: 0.4286 - val_loss: 0.6161 - val_precision_1: 1.0000 - val_recall_1: 0.2727\r\n",
      "Epoch 27/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.6894 - loss: 0.5405 - precision_1: 0.8660 - recall_1: 0.4532 - val_acc: 0.6429 - val_loss: 0.5750 - val_precision_1: 1.0000 - val_recall_1: 0.5455\r\n",
      "Epoch 28/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.7370 - loss: 0.5214 - precision_1: 0.8361 - recall_1: 0.5737 - val_acc: 0.4286 - val_loss: 0.6148 - val_precision_1: 1.0000 - val_recall_1: 0.2727\r\n",
      "Epoch 29/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.4889 - loss: 0.5645 - precision_1: 0.6786 - recall_1: 0.0950 - val_acc: 0.2143 - val_loss: 0.6433 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\r\n",
      "Epoch 30/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5887 - loss: 0.4958 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_acc: 0.2143 - val_loss: 0.6394 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\r\n",
      "Epoch 31/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.5852 - loss: 0.4993 - precision_1: 0.3333 - recall_1: 0.0439 - val_acc: 0.6429 - val_loss: 0.5937 - val_precision_1: 1.0000 - val_recall_1: 0.5455\r\n",
      "Epoch 32/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.7207 - loss: 0.5170 - precision_1: 0.8156 - recall_1: 0.5503 - val_acc: 0.7857 - val_loss: 0.5772 - val_precision_1: 1.0000 - val_recall_1: 0.7273\r\n",
      "Test accuracy: 65.22%\r\n",
      "Test precision: 41.66666567325592%\r\n",
      "Test recall: 83.33333134651184%\r\n",
      "Saved: 15645 params\r\n",
      "Test model loaded from weights\r\n",
      "Tensor(\"GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 311ms/step\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(None, 32), dtype=float32)\r\n",
      "Result: Acc=0.5947  F1=0.5208  AUC=0.6408\r\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T19:17:39.899303Z",
     "start_time": "2025-10-08T19:17:31.755284Z"
    }
   },
   "cell_type": "code",
   "source": "!python test.py",
   "id": "eea6aaf04f5b9b84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ruixiang/PycharmProjects/SCAR/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\r\n",
      "  warnings.warn(\r\n",
      "Found 6 dataset(s): ['AES_PPRM1', 'AES_PPRM3', 'AES_TBL', 'PRESENT', 'RSA', 'SABER']\r\n",
      "Testing AES_PPRM1: read ../test/AES_PPRM1_features.csv and ../test/AES_PPRM1_edges.csv\r\n",
      "Tensor(\"GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 334ms/step\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(None, 32), dtype=float32)\r\n",
      "Testing AES_PPRM3: read ../test/AES_PPRM3_features.csv and ../test/AES_PPRM3_edges.csv\r\n",
      "Tensor(\"GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 303ms/step\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(None, 32), dtype=float32)\r\n",
      "Testing AES_TBL: read ../test/AES_TBL_features.csv and ../test/AES_TBL_edges.csv\r\n",
      "Tensor(\"GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 299ms/step\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(None, 32), dtype=float32)\r\n",
      "Testing PRESENT: read ../test/PRESENT_features.csv and ../test/PRESENT_edges.csv\r\n",
      "Tensor(\"GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 309ms/step\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(None, 32), dtype=float32)\r\n",
      "WARNING:tensorflow:5 out of the last 18 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x14da0f550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\n",
      "Testing RSA: read ../test/RSA_features.csv and ../test/RSA_edges.csv\r\n",
      "Tensor(\"GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x14de834c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 301ms/step\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(None, 32), dtype=float32)\r\n",
      "Testing SABER: read ../test/SABER_features.csv and ../test/SABER_edges.csv\r\n",
      "Tensor(\"GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 302ms/step\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(None, 32), dtype=float32)\r\n",
      "for AES_PPRM1: Acc=0.7273  F1=0.7458  AUC=0.7576\r\n",
      "for AES_PPRM3: Acc=0.9639  F1=0.9807  AUC=0.6518\r\n",
      "for AES_TBL: Acc=0.7455  F1=0.7667  AUC=0.7819\r\n",
      "for PRESENT: Acc=0.3006  F1=0.3596  AUC=0.2876\r\n",
      "for RSA: Acc=0.5728  F1=0.2353  AUC=0.5086\r\n",
      "for SABER: Acc=0.9323  F1=0.9624  AUC=0.9494\r\n"
     ]
    }
   ],
   "execution_count": 104
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
