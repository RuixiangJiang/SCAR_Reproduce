{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T16:05:16.336409Z",
     "start_time": "2025-10-08T16:04:29.662698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!python Feature_Extract.py aes128_table_ecb key_in\n",
    "\n",
    "!python Feature_Extract.py AES_PPRM1 Kin AES_PPRM1\n",
    "!python Feature_Extract.py AES_PPRM3 Kin AES_PPRM3\n",
    "!python Feature_Extract.py AES_TBL Kin AES_TBL\n",
    "!python Feature_Extract.py RSA Kin RSA\n",
    "!python Feature_Extract.py SABER pol_64bit_in SABER # change PLC's label to 0 manually\n",
    "!python Feature_Extract.py PRESENT key PRESENT"
   ],
   "id": "20a0d4c2da617730",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ruixiang/PycharmProjects/SCAR/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\r\n",
      "  warnings.warn(\r\n",
      "Loading cached VCD object from: ../data/aes128_table_ecb/aes128_table_ecb_vcd.pkl\r\n",
      "Loading toggle counts from cache: ../data/aes128_table_ecb/aes128_table_ecb_toggle.txt\r\n",
      "Successfully loaded toggle counts from cache.\r\n",
      "[INFO] Features written to ../out/features.csv\r\n",
      "[INFO] Edges written to ../out/edges.csv\r\n",
      "/Users/ruixiang/PycharmProjects/SCAR/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\r\n",
      "  warnings.warn(\r\n",
      "Loading cached VCD object from: ../data/AES_PPRM1/AES_PPRM1_vcd.pkl\r\n",
      "Loading toggle counts from cache: ../data/AES_PPRM1/AES_PPRM1_toggle.txt\r\n",
      "Successfully loaded toggle counts from cache.\r\n",
      "[INFO] Features written to ../test/AES_PPRM1_features.csv\r\n",
      "[INFO] Edges written to ../test/AES_PPRM1_edges.csv\r\n",
      "/Users/ruixiang/PycharmProjects/SCAR/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\r\n",
      "  warnings.warn(\r\n",
      "Loading cached VCD object from: ../data/AES_PPRM3/AES_PPRM3_vcd.pkl\r\n",
      "Loading toggle counts from cache: ../data/AES_PPRM3/AES_PPRM3_toggle.txt\r\n",
      "Successfully loaded toggle counts from cache.\r\n",
      "[INFO] Features written to ../test/AES_PPRM3_features.csv\r\n",
      "[INFO] Edges written to ../test/AES_PPRM3_edges.csv\r\n",
      "/Users/ruixiang/PycharmProjects/SCAR/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\r\n",
      "  warnings.warn(\r\n",
      "Loading cached VCD object from: ../data/AES_TBL/AES_TBL_vcd.pkl\r\n",
      "Loading toggle counts from cache: ../data/AES_TBL/AES_TBL_toggle.txt\r\n",
      "Successfully loaded toggle counts from cache.\r\n",
      "[INFO] Features written to ../test/AES_TBL_features.csv\r\n",
      "[INFO] Edges written to ../test/AES_TBL_edges.csv\r\n",
      "/Users/ruixiang/PycharmProjects/SCAR/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\r\n",
      "  warnings.warn(\r\n",
      "Loading cached VCD object from: ../data/RSA/RSA_vcd.pkl\r\n",
      "Loading toggle counts from cache: ../data/RSA/RSA_toggle.txt\r\n",
      "Successfully loaded toggle counts from cache.\r\n",
      "[INFO] Features written to ../test/RSA_features.csv\r\n",
      "[INFO] Edges written to ../test/RSA_edges.csv\r\n",
      "/Users/ruixiang/PycharmProjects/SCAR/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\r\n",
      "  warnings.warn(\r\n",
      "Loading cached VCD object from: ../data/SABER/SABER_vcd.pkl\r\n",
      "Loading toggle counts from cache: ../data/SABER/SABER_toggle.txt\r\n",
      "Successfully loaded toggle counts from cache.\r\n",
      "[INFO] Features written to ../test/SABER_features.csv\r\n",
      "[INFO] Edges written to ../test/SABER_edges.csv\r\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T19:54:10.124350Z",
     "start_time": "2025-10-08T19:53:57.984945Z"
    }
   },
   "cell_type": "code",
   "source": "!python SCAR_GNN.py",
   "id": "36d97c0413864c34",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ruixiang/PycharmProjects/SCAR/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\r\n",
      "  warnings.warn(\r\n",
      "num_features: 7, num_classes: 2\r\n",
      "feature_names: ['Degree', 'Hamming distance', 'Paths', 'and', 'mux', 'or', 'xor']\r\n",
      "Train label distribution:\r\n",
      "label\r\n",
      "0    66\r\n",
      "1    66\r\n",
      "Name: count, dtype: int64\r\n",
      "\r\n",
      "Test label distribution:\r\n",
      "label\r\n",
      "0    17\r\n",
      "1     6\r\n",
      "Name: count, dtype: int64\r\n",
      "Epoch 1/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 48ms/step - acc: 0.5210 - loss: 7.3581 - precision: 0.3421 - recall: 0.0790 - val_acc: 0.2143 - val_loss: 12.6642 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 2/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.4843 - loss: 8.1573 - precision: 0.1405 - recall: 0.0118 - val_acc: 0.2143 - val_loss: 10.5382 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 3/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.6137 - loss: 6.0633 - precision: 0.7330 - recall: 0.1373 - val_acc: 0.2143 - val_loss: 7.5575 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 4/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5203 - loss: 7.2589 - precision: 0.3599 - recall: 0.0727 - val_acc: 0.2143 - val_loss: 7.4800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 5/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5474 - loss: 6.6168 - precision: 0.6429 - recall: 0.0990 - val_acc: 0.2857 - val_loss: 7.2555 - val_precision: 1.0000 - val_recall: 0.0909\r\n",
      "Epoch 6/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5162 - loss: 6.4130 - precision: 0.3683 - recall: 0.0583 - val_acc: 0.2857 - val_loss: 9.4161 - val_precision: 1.0000 - val_recall: 0.0909\r\n",
      "Epoch 7/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5390 - loss: 6.8261 - precision: 0.2468 - recall: 0.0542 - val_acc: 0.2857 - val_loss: 9.5007 - val_precision: 1.0000 - val_recall: 0.0909\r\n",
      "Epoch 8/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.4791 - loss: 7.5575 - precision: 0.1791 - recall: 0.0295 - val_acc: 0.2857 - val_loss: 10.5288 - val_precision: 1.0000 - val_recall: 0.0909\r\n",
      "Epoch 9/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.4849 - loss: 7.6992 - precision: 0.2857 - recall: 0.0389 - val_acc: 0.2857 - val_loss: 10.6215 - val_precision: 1.0000 - val_recall: 0.0909\r\n",
      "Epoch 10/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5582 - loss: 6.5809 - precision: 0.6442 - recall: 0.1174 - val_acc: 0.2857 - val_loss: 11.5129 - val_precision: 1.0000 - val_recall: 0.0909\r\n",
      "Epoch 11/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5021 - loss: 7.7597 - precision: 0.3214 - recall: 0.0345 - val_acc: 0.2857 - val_loss: 11.5129 - val_precision: 1.0000 - val_recall: 0.0909\r\n",
      "Epoch 12/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.4696 - loss: 7.8222 - precision: 0.2161 - recall: 0.0385 - val_acc: 0.2857 - val_loss: 11.5129 - val_precision: 1.0000 - val_recall: 0.0909\r\n",
      "Epoch 13/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.4813 - loss: 8.1909 - precision: 0.1048 - recall: 0.0119 - val_acc: 0.2857 - val_loss: 11.5129 - val_precision: 1.0000 - val_recall: 0.0909\r\n",
      "Epoch 14/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.4842 - loss: 7.9439 - precision: 0.3231 - recall: 0.0607 - val_acc: 0.2857 - val_loss: 11.5129 - val_precision: 1.0000 - val_recall: 0.0909\r\n",
      "Epoch 15/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.6027 - loss: 5.9330 - precision: 0.6673 - recall: 0.1378 - val_acc: 0.2857 - val_loss: 11.5129 - val_precision: 1.0000 - val_recall: 0.0909\r\n",
      "Epoch 16/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.4869 - loss: 7.7493 - precision: 0.3603 - recall: 0.0537 - val_acc: 0.2857 - val_loss: 11.5129 - val_precision: 1.0000 - val_recall: 0.0909\r\n",
      "Epoch 17/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5877 - loss: 6.3057 - precision: 0.7924 - recall: 0.2132 - val_acc: 0.2857 - val_loss: 11.5129 - val_precision: 1.0000 - val_recall: 0.0909\r\n",
      "Epoch 18/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5013 - loss: 7.1798 - precision: 0.3289 - recall: 0.0563 - val_acc: 0.2857 - val_loss: 11.5129 - val_precision: 1.0000 - val_recall: 0.0909\r\n",
      "Epoch 19/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.4423 - loss: 8.6470 - precision: 0.2177 - recall: 0.0319 - val_acc: 0.2857 - val_loss: 11.5129 - val_precision: 1.0000 - val_recall: 0.0909\r\n",
      "Epoch 20/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5028 - loss: 7.2005 - precision: 0.3429 - recall: 0.0528 - val_acc: 0.2857 - val_loss: 11.5129 - val_precision: 1.0000 - val_recall: 0.0909\r\n",
      "Epoch 21/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5257 - loss: 7.0687 - precision: 0.5579 - recall: 0.1091 - val_acc: 0.2857 - val_loss: 11.5129 - val_precision: 1.0000 - val_recall: 0.0909\r\n",
      "Epoch 22/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5117 - loss: 7.2955 - precision: 0.6639 - recall: 0.1091 - val_acc: 0.2857 - val_loss: 11.5129 - val_precision: 1.0000 - val_recall: 0.0909\r\n",
      "Epoch 23/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.4823 - loss: 7.9043 - precision: 0.2040 - recall: 0.0328 - val_acc: 0.2857 - val_loss: 11.5129 - val_precision: 1.0000 - val_recall: 0.0909\r\n",
      "Epoch 24/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.4939 - loss: 7.5936 - precision: 0.2650 - recall: 0.0562 - val_acc: 0.2857 - val_loss: 11.5129 - val_precision: 1.0000 - val_recall: 0.0909\r\n",
      "Epoch 25/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5262 - loss: 6.9470 - precision: 0.4189 - recall: 0.1331 - val_acc: 0.2857 - val_loss: 11.5129 - val_precision: 1.0000 - val_recall: 0.0909\r\n",
      "Epoch 26/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.4591 - loss: 7.7781 - precision: 0.3213 - recall: 0.1082 - val_acc: 0.2857 - val_loss: 11.5129 - val_precision: 1.0000 - val_recall: 0.0909\r\n",
      "Epoch 27/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5410 - loss: 6.9298 - precision: 0.3852 - recall: 0.1038 - val_acc: 0.2857 - val_loss: 11.5129 - val_precision: 1.0000 - val_recall: 0.0909\r\n",
      "Epoch 28/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.4922 - loss: 7.6227 - precision: 0.4981 - recall: 0.1424 - val_acc: 0.2857 - val_loss: 11.5129 - val_precision: 1.0000 - val_recall: 0.0909\r\n",
      "Epoch 29/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.4912 - loss: 6.7063 - precision: 0.4574 - recall: 0.1119 - val_acc: 0.2857 - val_loss: 11.5129 - val_precision: 1.0000 - val_recall: 0.0909\r\n",
      "Epoch 30/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.4960 - loss: 7.0539 - precision: 0.4336 - recall: 0.0965 - val_acc: 0.2857 - val_loss: 11.5129 - val_precision: 1.0000 - val_recall: 0.0909\r\n",
      "Epoch 31/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.4902 - loss: 7.3499 - precision: 0.4512 - recall: 0.0998 - val_acc: 0.2857 - val_loss: 11.5142 - val_precision: 1.0000 - val_recall: 0.0909\r\n",
      "Epoch 32/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5956 - loss: 6.0476 - precision: 0.7667 - recall: 0.1705 - val_acc: 0.2857 - val_loss: 11.5139 - val_precision: 1.0000 - val_recall: 0.0909\r\n",
      "Epoch 1/32\r\n",
      "Tensor(\"GatherV2:0\", shape=(None, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(None, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(None, 32), dtype=float32)\r\n",
      "\u001B[1m1/6\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m14s\u001B[0m 3s/step - acc: 0.9500 - loss: 0.4749 - precision_1: 0.9091 - recall_1: 1.0000Tensor(\"gnn_model_1/GatherV2:0\", shape=(None, 32), dtype=float32)\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 56ms/step - acc: 0.8778 - loss: 0.6097 - precision_1: 0.7997 - recall_1: 1.0000 - val_acc: 1.0000 - val_loss: 0.5144 - val_precision_1: 1.0000 - val_recall_1: 1.0000\r\n",
      "Epoch 2/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.8405 - loss: 0.5422 - precision_1: 0.8187 - recall_1: 0.8220 - val_acc: 0.2143 - val_loss: 0.6573 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\r\n",
      "Epoch 3/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5450 - loss: 0.5207 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_acc: 0.2143 - val_loss: 0.6739 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\r\n",
      "Epoch 4/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.5321 - loss: 0.5608 - precision_1: 0.3740 - recall_1: 0.0639 - val_acc: 0.7143 - val_loss: 0.5948 - val_precision_1: 1.0000 - val_recall_1: 0.6364\r\n",
      "Epoch 5/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.8294 - loss: 0.5303 - precision_1: 0.8718 - recall_1: 0.7589 - val_acc: 1.0000 - val_loss: 0.5545 - val_precision_1: 1.0000 - val_recall_1: 1.0000\r\n",
      "Epoch 6/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.8998 - loss: 0.5444 - precision_1: 0.8272 - recall_1: 0.9881 - val_acc: 1.0000 - val_loss: 0.5756 - val_precision_1: 1.0000 - val_recall_1: 1.0000\r\n",
      "Epoch 7/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.8570 - loss: 0.5398 - precision_1: 0.8983 - recall_1: 0.7609 - val_acc: 0.4286 - val_loss: 0.6022 - val_precision_1: 1.0000 - val_recall_1: 0.2727\r\n",
      "Epoch 8/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.6632 - loss: 0.5381 - precision_1: 0.9117 - recall_1: 0.2640 - val_acc: 0.9286 - val_loss: 0.5925 - val_precision_1: 1.0000 - val_recall_1: 0.9091\r\n",
      "Epoch 9/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.9406 - loss: 0.5266 - precision_1: 0.8844 - recall_1: 1.0000 - val_acc: 1.0000 - val_loss: 0.5691 - val_precision_1: 1.0000 - val_recall_1: 1.0000\r\n",
      "Epoch 10/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.9252 - loss: 0.5317 - precision_1: 0.8696 - recall_1: 1.0000 - val_acc: 1.0000 - val_loss: 0.5498 - val_precision_1: 1.0000 - val_recall_1: 1.0000\r\n",
      "Epoch 11/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.9052 - loss: 0.5024 - precision_1: 0.8247 - recall_1: 1.0000 - val_acc: 1.0000 - val_loss: 0.5569 - val_precision_1: 1.0000 - val_recall_1: 1.0000\r\n",
      "Epoch 12/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.9165 - loss: 0.5272 - precision_1: 0.8557 - recall_1: 1.0000 - val_acc: 0.8571 - val_loss: 0.5839 - val_precision_1: 1.0000 - val_recall_1: 0.8182\r\n",
      "Epoch 13/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.8561 - loss: 0.5151 - precision_1: 0.9178 - recall_1: 0.7390 - val_acc: 0.7857 - val_loss: 0.5967 - val_precision_1: 1.0000 - val_recall_1: 0.7273\r\n",
      "Epoch 14/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.8228 - loss: 0.5257 - precision_1: 0.8823 - recall_1: 0.7666 - val_acc: 1.0000 - val_loss: 0.5308 - val_precision_1: 1.0000 - val_recall_1: 1.0000\r\n",
      "Epoch 15/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.8407 - loss: 0.5090 - precision_1: 0.7350 - recall_1: 1.0000 - val_acc: 1.0000 - val_loss: 0.5377 - val_precision_1: 1.0000 - val_recall_1: 1.0000\r\n",
      "Epoch 16/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.9025 - loss: 0.5065 - precision_1: 0.8373 - recall_1: 1.0000 - val_acc: 1.0000 - val_loss: 0.5287 - val_precision_1: 1.0000 - val_recall_1: 1.0000\r\n",
      "Epoch 17/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.8493 - loss: 0.4985 - precision_1: 0.7245 - recall_1: 1.0000 - val_acc: 0.9286 - val_loss: 0.5467 - val_precision_1: 1.0000 - val_recall_1: 0.9091\r\n",
      "Epoch 18/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.8903 - loss: 0.4835 - precision_1: 0.8039 - recall_1: 1.0000 - val_acc: 0.9286 - val_loss: 0.5345 - val_precision_1: 1.0000 - val_recall_1: 0.9091\r\n",
      "Epoch 19/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.8983 - loss: 0.4954 - precision_1: 0.8224 - recall_1: 1.0000 - val_acc: 0.9286 - val_loss: 0.5364 - val_precision_1: 1.0000 - val_recall_1: 0.9091\r\n",
      "Epoch 20/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.9334 - loss: 0.5134 - precision_1: 0.8933 - recall_1: 0.9836 - val_acc: 0.9286 - val_loss: 0.5646 - val_precision_1: 1.0000 - val_recall_1: 0.9091\r\n",
      "Epoch 21/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.9235 - loss: 0.5184 - precision_1: 0.8834 - recall_1: 0.9768 - val_acc: 0.9286 - val_loss: 0.5304 - val_precision_1: 1.0000 - val_recall_1: 0.9091\r\n",
      "Epoch 22/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.9037 - loss: 0.5081 - precision_1: 0.8351 - recall_1: 1.0000 - val_acc: 0.9286 - val_loss: 0.5383 - val_precision_1: 1.0000 - val_recall_1: 0.9091\r\n",
      "Epoch 23/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.9002 - loss: 0.5174 - precision_1: 0.8414 - recall_1: 1.0000 - val_acc: 0.9286 - val_loss: 0.5255 - val_precision_1: 1.0000 - val_recall_1: 0.9091\r\n",
      "Epoch 24/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.9369 - loss: 0.4883 - precision_1: 0.8819 - recall_1: 1.0000 - val_acc: 0.9286 - val_loss: 0.5362 - val_precision_1: 1.0000 - val_recall_1: 0.9091\r\n",
      "Epoch 25/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.9426 - loss: 0.5012 - precision_1: 0.8998 - recall_1: 0.9948 - val_acc: 0.9286 - val_loss: 0.5358 - val_precision_1: 1.0000 - val_recall_1: 0.9091\r\n",
      "Epoch 26/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.9231 - loss: 0.4737 - precision_1: 0.8736 - recall_1: 0.9760 - val_acc: 0.9286 - val_loss: 0.5155 - val_precision_1: 1.0000 - val_recall_1: 0.9091\r\n",
      "Epoch 27/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.8793 - loss: 0.4876 - precision_1: 0.8047 - recall_1: 1.0000 - val_acc: 1.0000 - val_loss: 0.4962 - val_precision_1: 1.0000 - val_recall_1: 1.0000\r\n",
      "Epoch 28/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.8501 - loss: 0.4657 - precision_1: 0.7558 - recall_1: 1.0000 - val_acc: 1.0000 - val_loss: 0.5037 - val_precision_1: 1.0000 - val_recall_1: 1.0000\r\n",
      "Epoch 29/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.9209 - loss: 0.5179 - precision_1: 0.8825 - recall_1: 0.9724 - val_acc: 0.7857 - val_loss: 0.5718 - val_precision_1: 1.0000 - val_recall_1: 0.7273\r\n",
      "Epoch 30/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.9150 - loss: 0.4826 - precision_1: 0.8914 - recall_1: 0.9349 - val_acc: 0.9286 - val_loss: 0.5286 - val_precision_1: 1.0000 - val_recall_1: 0.9091\r\n",
      "Epoch 31/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.9406 - loss: 0.4784 - precision_1: 0.8877 - recall_1: 1.0000 - val_acc: 0.9286 - val_loss: 0.5033 - val_precision_1: 1.0000 - val_recall_1: 0.9091\r\n",
      "Epoch 32/32\r\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.9216 - loss: 0.4698 - precision_1: 0.8550 - recall_1: 1.0000 - val_acc: 0.9286 - val_loss: 0.5048 - val_precision_1: 1.0000 - val_recall_1: 0.9091\r\n",
      "Test accuracy: 78.26%\r\n",
      "Test precision: 54.54545617103577%\r\n",
      "Test recall: 100.0%\r\n",
      "Saved: 15645 params\r\n",
      "Test model loaded from weights\r\n",
      "Tensor(\"GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 314ms/step\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(None, 32), dtype=float32)\r\n",
      "Result: Acc=0.8106  F1=0.7543  AUC=0.8228\r\n"
     ]
    }
   ],
   "execution_count": 141
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T19:54:17.650704Z",
     "start_time": "2025-10-08T19:54:11.203997Z"
    }
   },
   "cell_type": "code",
   "source": "!python test.py",
   "id": "eea6aaf04f5b9b84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ruixiang/PycharmProjects/SCAR/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\r\n",
      "  warnings.warn(\r\n",
      "Found 6 dataset(s): ['AES_PPRM1', 'AES_PPRM3', 'AES_TBL', 'PRESENT', 'RSA', 'SABER']\r\n",
      "Testing AES_PPRM1: read ../test/AES_PPRM1_features.csv and ../test/AES_PPRM1_edges.csv\r\n",
      "Tensor(\"GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 311ms/step\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(None, 32), dtype=float32)\r\n",
      "Testing AES_PPRM3: read ../test/AES_PPRM3_features.csv and ../test/AES_PPRM3_edges.csv\r\n",
      "Tensor(\"GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 303ms/step\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(None, 32), dtype=float32)\r\n",
      "Testing AES_TBL: read ../test/AES_TBL_features.csv and ../test/AES_TBL_edges.csv\r\n",
      "Tensor(\"GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 304ms/step\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(None, 32), dtype=float32)\r\n",
      "Testing PRESENT: read ../test/PRESENT_features.csv and ../test/PRESENT_edges.csv\r\n",
      "Tensor(\"GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 310ms/step\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(None, 32), dtype=float32)\r\n",
      "WARNING:tensorflow:5 out of the last 18 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x16930e4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\n",
      "Testing RSA: read ../test/RSA_features.csv and ../test/RSA_edges.csv\r\n",
      "Tensor(\"GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x169883430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 312ms/step\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(None, 32), dtype=float32)\r\n",
      "Testing SABER: read ../test/SABER_features.csv and ../test/SABER_edges.csv\r\n",
      "Tensor(\"GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(1, 32), dtype=float32)\r\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 308ms/step\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(None, 32), dtype=float32)\r\n",
      "for AES_PPRM1: Acc=0.8000  F1=0.8000  AUC=0.7397\r\n",
      "for AES_PPRM3: Acc=0.7759  F1=0.8658  AUC=0.5248\r\n",
      "for AES_TBL: Acc=0.8182  F1=0.8214  AUC=0.7717\r\n",
      "for PRESENT: Acc=0.3006  F1=0.3596  AUC=0.4608\r\n",
      "for RSA: Acc=0.5845  F1=0.2403  AUC=0.5253\r\n",
      "for SABER: Acc=0.8934  F1=0.9430  AUC=0.9004\r\n"
     ]
    }
   ],
   "execution_count": 142
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
