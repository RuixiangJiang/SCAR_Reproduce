{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T01:52:48.984292Z",
     "start_time": "2025-09-29T01:52:35.971524Z"
    }
   },
   "cell_type": "code",
   "source": "!python SCAR_GNN.py",
   "id": "20a0d4c2da617730",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ruixiang/PycharmProjects/SCAR/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\r\n",
      "  warnings.warn(\r\n",
      "/Users/ruixiang/PycharmProjects/SCAR/src/SCAR_GNN.py:13: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\r\n",
      "  nodeset[\"label\"] = nodeset[\"node\"].str.contains(r\"(sbox|mixcolumn)\",case=False, na=False).astype(bool) \\\r\n",
      "/Users/ruixiang/PycharmProjects/SCAR/src/SCAR_GNN.py:14: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\r\n",
      "  | nodeset[\"Node\"].str.contains(r\"(sbox|mixcolumn)\",case=False, na=False).astype(bool)\r\n",
      "feature names: {'Hamming distance', 'Paths', 'xor', 'and', 'mux', 'Degree', 'or'}\r\n",
      "num_features: 7, num_classes: 2\r\n",
      "feature_names: {'Hamming distance', 'Paths', 'xor', 'and', 'mux', 'Degree', 'or'}\r\n",
      "x_train: [[ 0  0  0 ...  0  4  0]\r\n",
      " [ 0  0  1 ...  0  1  0]\r\n",
      " [ 2 31  0 ...  0  2  0]\r\n",
      " ...\r\n",
      " [ 0  0  0 ...  1  2  0]\r\n",
      " [ 0  0  0 ...  0  2  0]\r\n",
      " [ 0  0  0 ...  0  4  0]]\r\n",
      "Epoch 1/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 29ms/step - acc: 0.2866 - loss: 10.2860 - precision: 0.1412 - recall: 0.8955 - val_acc: 0.3500 - val_loss: 7.0093 - val_precision: 0.1429 - val_recall: 0.6667\r\n",
      "Epoch 2/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.3546 - loss: 9.6486 - precision: 0.1318 - recall: 0.7731 - val_acc: 0.4500 - val_loss: 8.1590 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 3/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.2628 - loss: 10.3567 - precision: 0.0785 - recall: 0.7803 - val_acc: 0.5000 - val_loss: 7.3181 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 4/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.2882 - loss: 10.4107 - precision: 0.1407 - recall: 0.7309 - val_acc: 0.5000 - val_loss: 6.5118 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 5/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.2428 - loss: 10.5487 - precision: 0.0638 - recall: 0.3861 - val_acc: 0.5500 - val_loss: 6.5031 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 6/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.3494 - loss: 9.3113 - precision: 0.1654 - recall: 0.8659 - val_acc: 0.5500 - val_loss: 5.8204 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 7/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.3238 - loss: 9.7916 - precision: 0.1045 - recall: 0.6703 - val_acc: 0.5500 - val_loss: 5.0672 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 8/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.2906 - loss: 10.1339 - precision: 0.1139 - recall: 0.6255 - val_acc: 0.5500 - val_loss: 4.9532 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 9/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.3419 - loss: 9.1536 - precision: 0.1126 - recall: 0.7281 - val_acc: 0.6500 - val_loss: 3.4608 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 10/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.3597 - loss: 9.5856 - precision: 0.1291 - recall: 0.6773 - val_acc: 0.6500 - val_loss: 3.3954 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 11/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.3255 - loss: 10.3987 - precision: 0.1300 - recall: 0.7904 - val_acc: 0.7500 - val_loss: 3.3984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 12/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.4090 - loss: 8.6122 - precision: 0.1197 - recall: 0.6506 - val_acc: 0.7500 - val_loss: 3.4042 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 13/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.3471 - loss: 8.6267 - precision: 0.1466 - recall: 0.8124 - val_acc: 0.7500 - val_loss: 3.3681 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 14/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.3912 - loss: 8.8402 - precision: 0.1594 - recall: 0.6939 - val_acc: 0.7500 - val_loss: 3.3438 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 15/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.3822 - loss: 8.8986 - precision: 0.1228 - recall: 0.7855 - val_acc: 0.7000 - val_loss: 3.3385 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 16/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.4009 - loss: 8.4575 - precision: 0.1220 - recall: 0.5694 - val_acc: 0.7000 - val_loss: 3.3357 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 17/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.4683 - loss: 7.6992 - precision: 0.1997 - recall: 0.9635 - val_acc: 0.7000 - val_loss: 3.3327 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 18/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.3591 - loss: 9.4152 - precision: 0.1238 - recall: 0.6380 - val_acc: 0.7000 - val_loss: 3.3081 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 19/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.3762 - loss: 9.1319 - precision: 0.1172 - recall: 0.6884 - val_acc: 0.7500 - val_loss: 3.2873 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 20/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.3676 - loss: 9.3487 - precision: 0.1139 - recall: 0.5635 - val_acc: 0.7500 - val_loss: 3.2909 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 21/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.2912 - loss: 9.9368 - precision: 0.1140 - recall: 0.6232 - val_acc: 0.7500 - val_loss: 3.2996 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 22/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.4259 - loss: 8.6354 - precision: 0.1477 - recall: 0.8077 - val_acc: 0.7500 - val_loss: 3.2960 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 23/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.3867 - loss: 8.6252 - precision: 0.1233 - recall: 0.5797 - val_acc: 0.7500 - val_loss: 3.2912 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 24/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.4241 - loss: 7.8456 - precision: 0.1655 - recall: 0.8660 - val_acc: 0.7500 - val_loss: 3.2820 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 25/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.4202 - loss: 8.1849 - precision: 0.1795 - recall: 0.7919 - val_acc: 0.7500 - val_loss: 3.2624 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 26/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.4942 - loss: 6.7235 - precision: 0.1771 - recall: 0.6427 - val_acc: 0.7500 - val_loss: 3.2542 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 27/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.4800 - loss: 7.1720 - precision: 0.1215 - recall: 0.4624 - val_acc: 0.8000 - val_loss: 3.2499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 28/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.4111 - loss: 8.8110 - precision: 0.0739 - recall: 0.3719 - val_acc: 0.8000 - val_loss: 3.2508 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 29/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.4009 - loss: 8.4899 - precision: 0.1171 - recall: 0.5375 - val_acc: 0.7500 - val_loss: 3.2566 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 30/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.3620 - loss: 9.1173 - precision: 0.1028 - recall: 0.4587 - val_acc: 0.7500 - val_loss: 3.2591 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 31/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.4903 - loss: 7.1984 - precision: 0.1051 - recall: 0.7214 - val_acc: 0.8000 - val_loss: 3.2449 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 32/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.4396 - loss: 7.6349 - precision: 0.1283 - recall: 0.5886 - val_acc: 0.8000 - val_loss: 3.2432 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n",
      "Epoch 1/32\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(None, 32), dtype=float32)\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(None, 32), dtype=float32)\r\n",
      "\u001B[1m1/9\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m24s\u001B[0m 3s/step - acc: 0.1000 - loss: 6.2344 - precision_1: 0.1000 - recall_1: 0.1000Tensor(\"gnn_model_1/GatherV2:0\", shape=(20, 32), dtype=float32)\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 34ms/step - acc: 0.1214 - loss: 12.2304 - precision_1: 0.1214 - recall_1: 0.1214 - val_acc: 0.1500 - val_loss: 4.0804 - val_precision_1: 0.1500 - val_recall_1: 0.1500\r\n",
      "Epoch 2/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.1189 - loss: 10.9758 - precision_1: 0.1189 - recall_1: 0.1189 - val_acc: 0.1500 - val_loss: 3.5553 - val_precision_1: 0.1500 - val_recall_1: 0.1500\r\n",
      "Epoch 3/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.1180 - loss: 12.5437 - precision_1: 0.1180 - recall_1: 0.1180 - val_acc: 0.2500 - val_loss: 3.0145 - val_precision_1: 0.2500 - val_recall_1: 0.2500\r\n",
      "Epoch 4/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.2736 - loss: 9.6564 - precision_1: 0.2736 - recall_1: 0.2736 - val_acc: 0.4000 - val_loss: 2.4921 - val_precision_1: 0.4000 - val_recall_1: 0.4000\r\n",
      "Epoch 5/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.3976 - loss: 7.7639 - precision_1: 0.3976 - recall_1: 0.3976 - val_acc: 0.4500 - val_loss: 2.0312 - val_precision_1: 0.4500 - val_recall_1: 0.4500\r\n",
      "Epoch 6/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.4525 - loss: 7.3283 - precision_1: 0.4525 - recall_1: 0.4525 - val_acc: 0.5000 - val_loss: 1.6478 - val_precision_1: 0.5000 - val_recall_1: 0.5000\r\n",
      "Epoch 7/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.3774 - loss: 7.5315 - precision_1: 0.3774 - recall_1: 0.3774 - val_acc: 0.4500 - val_loss: 1.3313 - val_precision_1: 0.4500 - val_recall_1: 0.4500\r\n",
      "Epoch 8/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.3774 - loss: 4.9922 - precision_1: 0.3774 - recall_1: 0.3774 - val_acc: 0.7000 - val_loss: 1.0777 - val_precision_1: 0.7000 - val_recall_1: 0.7000\r\n",
      "Epoch 9/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.6125 - loss: 5.3819 - precision_1: 0.6125 - recall_1: 0.6125 - val_acc: 0.7500 - val_loss: 0.8655 - val_precision_1: 0.7500 - val_recall_1: 0.7500\r\n",
      "Epoch 10/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.6554 - loss: 3.3985 - precision_1: 0.6554 - recall_1: 0.6554 - val_acc: 0.7500 - val_loss: 0.7305 - val_precision_1: 0.7500 - val_recall_1: 0.7500\r\n",
      "Epoch 11/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.6810 - loss: 2.5380 - precision_1: 0.6810 - recall_1: 0.6810 - val_acc: 0.7500 - val_loss: 0.6421 - val_precision_1: 0.7500 - val_recall_1: 0.7500\r\n",
      "Epoch 12/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.6932 - loss: 1.6428 - precision_1: 0.6932 - recall_1: 0.6932 - val_acc: 0.7500 - val_loss: 0.5739 - val_precision_1: 0.7500 - val_recall_1: 0.7500\r\n",
      "Epoch 13/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.6946 - loss: 1.1969 - precision_1: 0.6946 - recall_1: 0.6946 - val_acc: 0.7500 - val_loss: 0.5215 - val_precision_1: 0.7500 - val_recall_1: 0.7500\r\n",
      "Epoch 14/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.6470 - loss: 0.8863 - precision_1: 0.6470 - recall_1: 0.6470 - val_acc: 0.7500 - val_loss: 0.4824 - val_precision_1: 0.7500 - val_recall_1: 0.7500\r\n",
      "Epoch 15/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.7573 - loss: 0.5749 - precision_1: 0.7573 - recall_1: 0.7573 - val_acc: 0.8000 - val_loss: 0.4521 - val_precision_1: 0.8000 - val_recall_1: 0.8000\r\n",
      "Epoch 16/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.8689 - loss: 0.3964 - precision_1: 0.8689 - recall_1: 0.8689 - val_acc: 0.8500 - val_loss: 0.4354 - val_precision_1: 0.8500 - val_recall_1: 0.8500\r\n",
      "Epoch 17/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.8472 - loss: 0.3769 - precision_1: 0.8472 - recall_1: 0.8472 - val_acc: 0.8500 - val_loss: 0.4245 - val_precision_1: 0.8500 - val_recall_1: 0.8500\r\n",
      "Epoch 18/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.8828 - loss: 0.3382 - precision_1: 0.8828 - recall_1: 0.8828 - val_acc: 0.8500 - val_loss: 0.4159 - val_precision_1: 0.8500 - val_recall_1: 0.8500\r\n",
      "Epoch 19/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.8758 - loss: 0.3368 - precision_1: 0.8758 - recall_1: 0.8758 - val_acc: 0.8500 - val_loss: 0.4086 - val_precision_1: 0.8500 - val_recall_1: 0.8500\r\n",
      "Epoch 20/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.8770 - loss: 0.3177 - precision_1: 0.8770 - recall_1: 0.8770 - val_acc: 0.9000 - val_loss: 0.4019 - val_precision_1: 0.9000 - val_recall_1: 0.9000\r\n",
      "Epoch 21/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.9387 - loss: 0.3549 - precision_1: 0.9387 - recall_1: 0.9387 - val_acc: 0.9000 - val_loss: 0.3958 - val_precision_1: 0.9000 - val_recall_1: 0.9000\r\n",
      "Epoch 22/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.9638 - loss: 0.2941 - precision_1: 0.9638 - recall_1: 0.9638 - val_acc: 0.9000 - val_loss: 0.3899 - val_precision_1: 0.9000 - val_recall_1: 0.9000\r\n",
      "Epoch 23/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.9574 - loss: 0.3203 - precision_1: 0.9574 - recall_1: 0.9574 - val_acc: 0.9000 - val_loss: 0.3846 - val_precision_1: 0.9000 - val_recall_1: 0.9000\r\n",
      "Epoch 24/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.9499 - loss: 0.3052 - precision_1: 0.9499 - recall_1: 0.9499 - val_acc: 0.9000 - val_loss: 0.3790 - val_precision_1: 0.9000 - val_recall_1: 0.9000\r\n",
      "Epoch 25/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.9535 - loss: 0.2980 - precision_1: 0.9535 - recall_1: 0.9535 - val_acc: 0.9000 - val_loss: 0.3735 - val_precision_1: 0.9000 - val_recall_1: 0.9000\r\n",
      "Epoch 26/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.9701 - loss: 0.2908 - precision_1: 0.9701 - recall_1: 0.9701 - val_acc: 0.9000 - val_loss: 0.3684 - val_precision_1: 0.9000 - val_recall_1: 0.9000\r\n",
      "Epoch 27/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.9644 - loss: 0.2659 - precision_1: 0.9644 - recall_1: 0.9644 - val_acc: 0.9000 - val_loss: 0.3635 - val_precision_1: 0.9000 - val_recall_1: 0.9000\r\n",
      "Epoch 28/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.9449 - loss: 0.2933 - precision_1: 0.9449 - recall_1: 0.9449 - val_acc: 0.9000 - val_loss: 0.3589 - val_precision_1: 0.9000 - val_recall_1: 0.9000\r\n",
      "Epoch 29/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.9345 - loss: 0.2972 - precision_1: 0.9345 - recall_1: 0.9345 - val_acc: 0.9000 - val_loss: 0.3544 - val_precision_1: 0.9000 - val_recall_1: 0.9000\r\n",
      "Epoch 30/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.9428 - loss: 0.2937 - precision_1: 0.9428 - recall_1: 0.9428 - val_acc: 0.9000 - val_loss: 0.3501 - val_precision_1: 0.9000 - val_recall_1: 0.9000\r\n",
      "Epoch 31/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.9437 - loss: 0.2832 - precision_1: 0.9437 - recall_1: 0.9437 - val_acc: 0.9000 - val_loss: 0.3457 - val_precision_1: 0.9000 - val_recall_1: 0.9000\r\n",
      "Epoch 32/32\r\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.9389 - loss: 0.2700 - precision_1: 0.9389 - recall_1: 0.9389 - val_acc: 0.9000 - val_loss: 0.3417 - val_precision_1: 0.9000 - val_recall_1: 0.9000\r\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(None, 32), dtype=float32)\r\n",
      "Test accuracy: 83.87%\r\n",
      "Test precision: 83.87096524238586%\r\n",
      "Test recall: 83.87096524238586%\r\n",
      "Saved: 15678 params\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T01:53:07.920914Z",
     "start_time": "2025-09-29T01:52:48.991913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!python Feature_Extract.py AES_PPRM1 Kin AES_PPRM1\n",
    "!python Feature_Extract.py AES_PPRM3 Kin AES_PPRM3\n",
    "!python Feature_Extract.py AES_TBL Kin AES_TBL\n",
    "!python Feature_Extract.py RSA Kin RSA\n",
    "!python Feature_Extract.py SABER pol_64bit_in SABER"
   ],
   "id": "94afc518a1662b0e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating LALR tables\r\n",
      "WARNING: 183 shift/reduce conflicts\r\n",
      "[INFO] Features written to ../test/AES_PPRM1_features.csv\r\n",
      "[INFO] Edges written to ../test/AES_PPRM1_edges.csv\r\n",
      "Generating LALR tables\r\n",
      "WARNING: 183 shift/reduce conflicts\r\n",
      "[INFO] Features written to ../test/AES_PPRM3_features.csv\r\n",
      "[INFO] Edges written to ../test/AES_PPRM3_edges.csv\r\n",
      "Generating LALR tables\r\n",
      "WARNING: 183 shift/reduce conflicts\r\n",
      "[INFO] Features written to ../test/AES_TBL_features.csv\r\n",
      "[INFO] Edges written to ../test/AES_TBL_edges.csv\r\n",
      "Generating LALR tables\r\n",
      "WARNING: 183 shift/reduce conflicts\r\n",
      "[INFO] Features written to ../test/RSA_features.csv\r\n",
      "[INFO] Edges written to ../test/RSA_edges.csv\r\n",
      "Generating LALR tables\r\n",
      "WARNING: 183 shift/reduce conflicts\r\n",
      "[INFO] Features written to ../test/SABER_features.csv\r\n",
      "[INFO] Edges written to ../test/SABER_edges.csv\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T01:55:36.026922Z",
     "start_time": "2025-09-29T01:55:35.386943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "from GNN import *\n",
    "from GraphInformation import *\n",
    "\n",
    "TEST_DIR = \"../test\"\n",
    "\n",
    "feature_files = sorted(glob.glob(os.path.join(TEST_DIR, \"*_features.csv\")))\n",
    "paired = []\n",
    "for fpath in feature_files:\n",
    "    base = os.path.basename(fpath).replace(\"_features.csv\", \"\")\n",
    "    epath = os.path.join(TEST_DIR, f\"{base}_edges.csv\")\n",
    "    if os.path.exists(epath):\n",
    "        paired.append((base, fpath, epath))\n",
    "\n",
    "if not paired:\n",
    "    print(\"No dataset pairs found under ./test (expect *_features.csv + *_edges.csv)\")\n",
    "else:\n",
    "    print(f\"Found {len(paired)} dataset(s):\", [b for b,_,_ in paired])\n",
    "\n",
    "leaky_module = {\n",
    "    \"AES_PPRM1\": [\"SBOX\", \"Mixcolumns\", \"MX\"],\n",
    "    \"AES_PPRM3\": [\"Sbox\", \"Mixcolumns\", \"MX\"],\n",
    "    \"AES_TBL\": [\"SBOX\", \"Mixcolumns\", \"MX\"],\n",
    "    \"RSA\": [\"MODEXP_SEQ\", \"MULT_BLK\"],\n",
    "    \"SABER\": [\"PMULTs\"]\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for base, ffeat, fedge in paired:\n",
    "    test_nodeset = pd.read_csv(ffeat)\n",
    "    test_edge = pd.read_csv(fedge)\n",
    "    keywords = leaky_module.get(base, [])\n",
    "    def contains_any(value, keywords):\n",
    "        return any(kw in str(value) for kw in keywords)\n",
    "    test_nodeset[\"label\"] = test_nodeset[\"node\"].apply(\n",
    "        lambda x: 1 if contains_any(x, keywords) else 0\n",
    "    )\n",
    "    test_nodeset.to_csv(ffeat, index=False)\n",
    "\n",
    "    (X, edges, edges_weights), feature_names, num_features, num_classes = graph_information(ffeat, fedge, \"test\")\n",
    "    Y = test_nodeset[\"label\"]\n",
    "\n",
    "    model = GNNNodeClassifier(\n",
    "        graph_info=(X, edges, edges_weights),\n",
    "        num_classes=num_classes,\n",
    "        hidden_units=hidden_units,\n",
    "        dropout_rate=dropout_rate,\n",
    "        name=\"gnn_model\",\n",
    "    )\n",
    "\n",
    "    haha = model(tf.convert_to_tensor([0], dtype=tf.int32))\n",
    "    model.load_weights(\"../out/gnn_weights.weights.h5\")\n",
    "\n",
    "    all_idx = tf.range(X.shape[0], dtype=tf.int32)\n",
    "    probs = model(all_idx).numpy()\n",
    "\n",
    "    if probs.shape[1] == 2:\n",
    "        y_pred = probs.argmax(axis=1)\n",
    "        score_for_pos = probs[:, 1]\n",
    "    else:\n",
    "        y_pred = (probs.squeeze(-1) >= 0.5).astype(np.int32)\n",
    "        score_for_pos = probs.squeeze(-1)\n",
    "\n",
    "    y_true = Y.argmax(1) if Y.ndim == 2 else Y\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1  = f1_score(y_true, y_pred)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, score_for_pos)\n",
    "    except Exception:\n",
    "        auc = float('nan')\n",
    "\n",
    "    results.append((base, acc, f1, auc))\n",
    "\n",
    "    test_nodeset[\"prediction\"] = y_pred\n",
    "    test_nodeset.to_csv(ffeat + \"_pred.csv\", index=False)\n",
    "\n",
    "for (base, acc, f1, auc) in results:\n",
    "    print(f\"for {base}: Acc={acc:.4f}  F1={f1:.4f}  AUC={auc:.4f}\")"
   ],
   "id": "bf482143490f9a3d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 dataset(s): ['AES_PPRM1', 'AES_PPRM3', 'AES_TBL', 'RSA', 'SABER']\n",
      "feature names: {'xor', 'Hamming distance', 'Paths', 'and', 'Degree', 'mux', 'or'}\n",
      "tf.Tensor(\n",
      "[[0.         0.26587725 0.2789782  0.23071173 0.         0.07762527\n",
      "  0.         0.         0.16926938 0.         0.         0.06415008\n",
      "  0.         0.04768961 0.         0.         0.20529015 0.\n",
      "  0.         0.12896045 0.2136614  0.33548328 0.         0.2149182\n",
      "  0.         0.41664055 0.         0.         0.39921975 0.\n",
      "  0.2957067  0.1447038 ]], shape=(1, 32), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[3.7214959e-01 0.0000000e+00 3.2070926e-01 ... 2.7103651e-01\n",
      "  1.6178074e-01 1.9439660e-01]\n",
      " [2.2295882e+02 1.0488976e+01 1.3457716e+02 ... 0.0000000e+00\n",
      "  1.6885191e+01 1.2171793e+02]\n",
      " [3.6440435e-01 0.0000000e+00 3.9555532e-01 ... 3.4809464e-01\n",
      "  1.4761160e-01 2.4913909e-01]\n",
      " ...\n",
      " [4.6152065e+01 1.9929228e+00 2.7410858e+01 ... 0.0000000e+00\n",
      "  3.4199588e+00 2.4908159e+01]\n",
      " [1.4770608e+01 4.7784790e-01 8.5403280e+00 ... 0.0000000e+00\n",
      "  1.0129911e+00 7.7974877e+00]\n",
      " [3.6440513e-01 0.0000000e+00 3.9555985e-01 ... 3.4752172e-01\n",
      "  1.4740555e-01 2.4939437e-01]], shape=(58, 32), dtype=float32)\n",
      "feature names: {'xor', 'Hamming distance', 'Paths', 'and', 'Degree', 'mux', 'or'}\n",
      "tf.Tensor(\n",
      "[[0.4635333  0.         0.95046103 0.         0.2603697  0.04359219\n",
      "  0.61406165 0.         0.562028   0.         0.12017764 0.1260693\n",
      "  0.         0.         0.         0.31543702 0.         1.4886078\n",
      "  0.08127513 0.         0.         0.         1.2107767  0.\n",
      "  0.08814596 1.004747   0.42321157 0.         0.34642932 0.\n",
      "  0.14705586 0.09394024]], shape=(1, 32), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[2.40351367e+00 1.12034909e-01 1.35665178e+00 ... 1.99936047e-01\n",
      "  1.58069674e-02 1.16192293e+00]\n",
      " [2.63467140e+01 6.30083859e-01 1.49616871e+01 ... 0.00000000e+00\n",
      "  1.60744917e+00 1.35917540e+01]\n",
      " [2.63467140e+01 6.30083859e-01 1.49616871e+01 ... 0.00000000e+00\n",
      "  1.60744917e+00 1.35917540e+01]\n",
      " ...\n",
      " [1.75728226e+01 1.98538899e-01 9.66241455e+00 ... 1.28096282e-01\n",
      "  9.48077619e-01 8.79654598e+00]\n",
      " [5.41375885e+01 2.31220865e+00 3.21190910e+01 ... 0.00000000e+00\n",
      "  3.94501019e+00 2.91104794e+01]\n",
      " [2.23332787e+00 1.10943325e-01 1.26893771e+00 ... 1.99880064e-01\n",
      "  1.10946177e-03 1.07152689e+00]], shape=(418, 32), dtype=float32)\n",
      "feature names: {'xor', 'Hamming distance', 'Paths', 'and', 'Degree', 'mux', 'or'}\n",
      "tf.Tensor(\n",
      "[[0.         0.45402145 0.         0.1421573  0.         0.07580078\n",
      "  0.         0.         0.1297159  0.         0.         0.\n",
      "  0.         0.2721069  1.0801755  0.1835293  0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.5399837  0.         0.3596903  0.34421402 0.\n",
      "  0.22602259 0.        ]], shape=(1, 32), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1.0789567e+00 9.8614588e-02 7.0361096e-01 ... 1.4629631e-01\n",
      "  1.0702246e-01 4.5060542e-01]\n",
      " [1.4095856e+01 4.4406700e-01 8.1326389e+00 ... 0.0000000e+00\n",
      "  9.6170008e-01 7.4291477e+00]\n",
      " [2.6447630e-01 0.0000000e+00 3.1901133e-01 ... 3.9090729e-01\n",
      "  1.3622360e-01 2.1337664e-01]\n",
      " ...\n",
      " [4.0820795e-01 7.5221375e-02 3.5216001e-01 ... 1.1840371e+00\n",
      "  4.6604660e-01 6.0500008e-01]\n",
      " [2.6323529e+02 1.2297859e+01 1.5870956e+02 ... 0.0000000e+00\n",
      "  1.9939922e+01 1.4363707e+02]\n",
      " [2.0108943e+02 9.4059801e+00 1.2111565e+02 ... 0.0000000e+00\n",
      "  1.5164118e+01 1.0959411e+02]], shape=(58, 32), dtype=float32)\n",
      "feature names: {'xor', 'Hamming distance', 'Paths', 'and', 'Degree', 'mux', 'or'}\n",
      "tf.Tensor(\n",
      "[[0.         0.3576657  0.20585877 0.41617638 0.05930055 0.\n",
      "  0.58600485 0.01089763 0.         0.         0.         0.\n",
      "  0.5920657  0.12040018 0.60202813 0.         0.58668584 0.\n",
      "  0.55053127 0.14822093 0.06587578 0.         0.50402427 0.06165784\n",
      "  0.47548422 0.8475988  0.23817945 0.11893379 0.83957946 0.39262396\n",
      "  0.4894286  0.        ]], shape=(1, 32), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[2.6408297e-01 0.0000000e+00 3.1832319e-01 ... 3.9019370e-01\n",
      "  1.3581043e-01 2.1332832e-01]\n",
      " [2.7803259e+00 0.0000000e+00 1.3810581e+00 ... 1.3164414e-01\n",
      "  2.6921209e-02 1.5141331e+00]\n",
      " [2.6402810e-01 0.0000000e+00 3.1825384e-01 ... 3.9010599e-01\n",
      "  1.3575919e-01 2.1331599e-01]\n",
      " ...\n",
      " [2.0887141e+00 3.1316999e-02 1.1169094e+00 ... 1.3568024e-01\n",
      "  2.6791353e-02 1.0042486e+00]\n",
      " [2.8324062e-01 0.0000000e+00 2.6025492e-01 ... 3.0327389e-01\n",
      "  1.9715343e-01 2.3384155e-01]\n",
      " [6.9211617e+01 3.0799057e+00 4.1468151e+01 ... 0.0000000e+00\n",
      "  5.1594310e+00 3.7543846e+01]], shape=(426, 32), dtype=float32)\n",
      "feature names: {'xor', 'Hamming distance', 'Paths', 'and', 'Degree', 'mux', 'or'}\n",
      "tf.Tensor(\n",
      "[[0.         3.8044739  0.         4.5616527  0.6003958  0.\n",
      "  0.15560108 0.         0.         0.         0.         0.4816769\n",
      "  2.6063454  5.5408015  9.346498   0.         0.         8.567702\n",
      "  1.3493966  0.         0.         0.         0.         1.1761351\n",
      "  0.         4.2142     0.         0.2657607  1.7442681  0.\n",
      "  1.3054569  0.        ]], shape=(1, 32), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[  8.651575    0.          2.9863212 ...   1.3658202   0.\n",
      "    6.4281683]\n",
      " [283.41193    13.514787  171.23137   ...   0.         21.518938\n",
      "  154.84276  ]\n",
      " [283.41193    13.514787  171.23137   ...   0.         21.518938\n",
      "  154.84276  ]\n",
      " ...\n",
      " [283.41193    13.514787  171.23137   ...   0.         21.518938\n",
      "  154.84276  ]\n",
      " [283.41193    13.514787  171.23137   ...   0.         21.518938\n",
      "  154.84276  ]\n",
      " [276.50366    13.18319   167.05038   ...   0.         20.993681\n",
      "  151.0636   ]], shape=(1182, 32), dtype=float32)\n",
      "for AES_PPRM1: Acc=0.7414  F1=0.7273  AUC=0.7632\n",
      "for AES_PPRM3: Acc=0.9641  F1=0.9806  AUC=0.7452\n",
      "for AES_TBL: Acc=0.7414  F1=0.7273  AUC=0.7632\n",
      "for RSA: Acc=0.6761  F1=0.1481  AUC=0.4575\n",
      "for SABER: Acc=0.9484  F1=0.9711  AUC=0.9304\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
