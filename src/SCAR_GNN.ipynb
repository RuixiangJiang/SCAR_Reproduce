{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-25T02:27:56.865210Z",
     "start_time": "2025-08-25T02:27:56.860119Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T02:27:56.911033Z",
     "start_time": "2025-08-25T02:27:56.908843Z"
    }
   },
   "cell_type": "code",
   "source": "file_name = \"aes128_table_ecb\"",
   "id": "e46967983e56faa6",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T02:27:56.926053Z",
     "start_time": "2025-08-25T02:27:56.921189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nodeset = pd.read_csv(f\"../out/features.csv\")\n",
    "df = pd.read_csv(f\"../out/edges.csv\")"
   ],
   "id": "bec0bd6db085eb26",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T02:27:56.956348Z",
     "start_time": "2025-08-25T02:27:56.949358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if \"label\" in nodeset.columns:\n",
    "    label = \"label\"\n",
    "else:\n",
    "    label = \"xor\" # suppose xor is the label\n",
    "# In the paper, nodes belonging to the Sbox and Mixcolumns modules are labeled as 1\n",
    "\n",
    "X = nodeset.drop(columns=[label])\n",
    "y = nodeset[label]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "class_values = sorted(nodeset[label].unique())\n",
    "class_idx = {name: id for id, name in enumerate(class_values)}\n",
    "paper_idx = {name: idx for idx, name in enumerate(sorted(nodeset[\"node_number\"].unique()))}\n",
    "\n",
    "nodeset[\"node_number\"] = nodeset[\"node_number\"].apply(lambda name: paper_idx[name])\n",
    "df[\"source\"] = df[\"source\"].apply(lambda name: paper_idx[name])\n",
    "df[\"target\"] = df[\"target\"].apply(lambda name: paper_idx[name])\n",
    "nodeset[label] = nodeset[label].apply(lambda value: class_idx[value])\n",
    "\n",
    "print(nodeset.xor.value_counts())"
   ],
   "id": "584a63c56f0b16b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xor\n",
      "0    172\n",
      "1     55\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T02:27:56.968469Z",
     "start_time": "2025-08-25T02:27:56.966561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = nodeset.iloc[0:173]\n",
    "test_data = nodeset.iloc[173:]"
   ],
   "id": "aca38d45d1dfa300",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T02:27:56.983173Z",
     "start_time": "2025-08-25T02:27:56.981104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hidden_units = [32, 32]\n",
    "learning_rate = 0.0001\n",
    "dropout_rate = 0.3\n",
    "num_epochs = 32\n",
    "batch_size = 20"
   ],
   "id": "38498a430d4e29ec",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T02:27:56.990950Z",
     "start_time": "2025-08-25T02:27:56.988306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_experiment(model, x_train, y_train):\n",
    "    # Compile the model.\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "        metrics=[keras.metrics.BinaryAccuracy(name=\"acc\"),\n",
    "keras.metrics.Precision(), keras.metrics.Recall()],\n",
    "    )\n",
    "    # Create an early stopping callback.\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_acc\", patience=50, restore_best_weights=True\n",
    "    )\n",
    "    # Fit the model.\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        epochs=num_epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.10,\n",
    "        callbacks=[early_stopping],\n",
    "    )\n",
    "\n",
    "    return history"
   ],
   "id": "ee389b4d92939c2d",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T02:27:56.998395Z",
     "start_time": "2025-08-25T02:27:56.995668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def display_learning_curves(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    ax1.plot(history.history[\"loss\"])\n",
    "    ax1.plot(history.history[\"val_loss\"])\n",
    "    ax1.legend([\"train\", \"test\"], loc=\"upper right\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "\n",
    "    ax2.plot(history.history[\"acc\"])\n",
    "    ax2.plot(history.history[\"val_acc\"])\n",
    "    ax2.legend([\"train\", \"test\"], loc=\"upper right\")\n",
    "    ax2.set_xlabel(\"Epochs\")\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    plt.show()"
   ],
   "id": "db00035001c7a259",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T02:27:57.006551Z",
     "start_time": "2025-08-25T02:27:57.004127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_ffn(hidden_units, dropout_rate, name=None):\n",
    "    fnn_layers = []\n",
    "\n",
    "    for units in hidden_units:\n",
    "        fnn_layers.append(layers.BatchNormalization())\n",
    "        fnn_layers.append(layers.Dropout(dropout_rate))\n",
    "        fnn_layers.append(layers.Dense(units, activation=tf.nn.relu))\n",
    "\n",
    "    return keras.Sequential(fnn_layers, name=name)"
   ],
   "id": "537e489acd6562a4",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T02:27:57.018694Z",
     "start_time": "2025-08-25T02:27:57.014089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feature_names = set(nodeset.columns) - {\"node_number\", \"Node\", \"node\", label}\n",
    "num_features = len(feature_names)\n",
    "num_classes = len(class_idx)\n",
    "\n",
    "print(train_data[list(feature_names)])\n",
    "# Create train and test features as a numpy array.\n",
    "x_train = train_data[list(feature_names)].to_numpy()\n",
    "x_test = test_data[list(feature_names)].to_numpy()\n",
    "#print(x_train)\n",
    "# Create train and test targets as a numpy array.\n",
    "y_train = train_data[label]\n",
    "y_test = test_data[label]"
   ],
   "id": "5bc80a83d9b0d489",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     or  and  Degree  mux  Hamming distance  Paths\n",
      "0     0    0      18    1              3607      0\n",
      "1     0    0       1    0                 0      0\n",
      "2     0    0       9    1              8747      1\n",
      "3     0    0       3    0                 0    510\n",
      "4     0    0       3    0                 0      0\n",
      "..   ..  ...     ...  ...               ...    ...\n",
      "168   0    0       4    0                 0      0\n",
      "169   0    0       2    0              1016     51\n",
      "170   0    0       2    0                 0      0\n",
      "171   0    0       1    0                 0      0\n",
      "172   0    0       8    0                 0      0\n",
      "\n",
      "[173 rows x 6 columns]\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T02:28:00.609747Z",
     "start_time": "2025-08-25T02:27:57.049143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_baseline_model(hidden_units, num_classes, dropout_rate=0.2):\n",
    "    inputs = layers.Input(shape=(num_features,), name=\"input_features\")\n",
    "    x = create_ffn(hidden_units, dropout_rate, name=f\"ffn_block1\")(inputs)\n",
    "    for block_idx in range(4):\n",
    "        # Create an FFN block.\n",
    "        x1 = create_ffn(hidden_units, dropout_rate, name=f\"ffn_block{block_idx + 2}\")(x)\n",
    "        # Add skip connection.\n",
    "        x = layers.Add(name=f\"skip_connection{block_idx + 2}\")([x, x1])\n",
    "    # Compute logits.\n",
    "    logits = layers.Dense(num_classes-1, name=\"logits\")(x)\n",
    "    # Create the model.\n",
    "    return keras.Model(inputs=inputs, outputs=logits, name=\"baseline\")\n",
    "\n",
    "\n",
    "baseline_model = create_baseline_model(hidden_units, num_classes, dropout_rate)\n",
    "baseline_model.summary()\n",
    "\n",
    "history = run_experiment(baseline_model, x_train, y_train)"
   ],
   "id": "a540e91d81dc91c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"baseline\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"baseline\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m   Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to     \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_features      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6\u001B[0m)         │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ffn_block1          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │      \u001B[38;5;34m1,432\u001B[0m │ input_features[\u001B[38;5;34m0\u001B[0m… │\n",
       "│ (\u001B[38;5;33mSequential\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ffn_block2          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │      \u001B[38;5;34m2,368\u001B[0m │ ffn_block1[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "│ (\u001B[38;5;33mSequential\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ skip_connection2    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ ffn_block1[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m], │\n",
       "│ (\u001B[38;5;33mAdd\u001B[0m)               │                   │            │ ffn_block2[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ffn_block3          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │      \u001B[38;5;34m2,368\u001B[0m │ skip_connection2… │\n",
       "│ (\u001B[38;5;33mSequential\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ skip_connection3    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ skip_connection2… │\n",
       "│ (\u001B[38;5;33mAdd\u001B[0m)               │                   │            │ ffn_block3[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ffn_block4          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │      \u001B[38;5;34m2,368\u001B[0m │ skip_connection3… │\n",
       "│ (\u001B[38;5;33mSequential\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ skip_connection4    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ skip_connection3… │\n",
       "│ (\u001B[38;5;33mAdd\u001B[0m)               │                   │            │ ffn_block4[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ffn_block5          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │      \u001B[38;5;34m2,368\u001B[0m │ skip_connection4… │\n",
       "│ (\u001B[38;5;33mSequential\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ skip_connection5    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ skip_connection4… │\n",
       "│ (\u001B[38;5;33mAdd\u001B[0m)               │                   │            │ ffn_block5[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ logits (\u001B[38;5;33mDense\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │         \u001B[38;5;34m33\u001B[0m │ skip_connection5… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_features      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ffn_block1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,432</span> │ input_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ffn_block2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,368</span> │ ffn_block1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ skip_connection2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ffn_block1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │                   │            │ ffn_block2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ffn_block3          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,368</span> │ skip_connection2… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ skip_connection3    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ skip_connection2… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │                   │            │ ffn_block3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ffn_block4          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,368</span> │ skip_connection3… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ skip_connection4    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ skip_connection3… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │                   │            │ ffn_block4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ffn_block5          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,368</span> │ skip_connection4… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ skip_connection5    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ skip_connection4… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │                   │            │ ffn_block5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ logits (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ skip_connection5… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m10,937\u001B[0m (42.72 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,937</span> (42.72 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m10,349\u001B[0m (40.43 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,349</span> (40.43 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m588\u001B[0m (2.30 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">588</span> (2.30 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 29ms/step - acc: 0.3186 - loss: 9.5923 - precision: 0.2332 - recall: 0.8082 - val_acc: 0.7778 - val_loss: 2.2790 - val_precision: 0.6000 - val_recall: 0.6000\n",
      "Epoch 2/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.3014 - loss: 10.1331 - precision: 0.2436 - recall: 0.7612 - val_acc: 0.7778 - val_loss: 2.2543 - val_precision: 0.6000 - val_recall: 0.6000\n",
      "Epoch 3/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.3599 - loss: 9.3231 - precision: 0.2660 - recall: 0.9185 - val_acc: 0.6111 - val_loss: 2.2364 - val_precision: 0.3333 - val_recall: 0.4000\n",
      "Epoch 4/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.3570 - loss: 9.3565 - precision: 0.3021 - recall: 0.8076 - val_acc: 0.6667 - val_loss: 2.2376 - val_precision: 0.4000 - val_recall: 0.4000\n",
      "Epoch 5/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.2954 - loss: 9.4507 - precision: 0.2155 - recall: 0.6757 - val_acc: 0.6111 - val_loss: 2.2988 - val_precision: 0.3750 - val_recall: 0.6000\n",
      "Epoch 6/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.3364 - loss: 9.0915 - precision: 0.2391 - recall: 0.8733 - val_acc: 0.4444 - val_loss: 2.4570 - val_precision: 0.2727 - val_recall: 0.6000\n",
      "Epoch 7/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.2932 - loss: 10.0782 - precision: 0.2097 - recall: 0.7845 - val_acc: 0.2778 - val_loss: 2.6440 - val_precision: 0.2500 - val_recall: 0.8000\n",
      "Epoch 8/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.3607 - loss: 9.2691 - precision: 0.2662 - recall: 0.8342 - val_acc: 0.2778 - val_loss: 2.8407 - val_precision: 0.2500 - val_recall: 0.8000\n",
      "Epoch 9/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.2996 - loss: 10.1869 - precision: 0.2156 - recall: 0.7335 - val_acc: 0.2778 - val_loss: 3.7221 - val_precision: 0.2500 - val_recall: 0.8000\n",
      "Epoch 10/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.3427 - loss: 9.3134 - precision: 0.2150 - recall: 0.8328 - val_acc: 0.2222 - val_loss: 4.4922 - val_precision: 0.2353 - val_recall: 0.8000\n",
      "Epoch 11/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.3975 - loss: 9.0980 - precision: 0.2765 - recall: 0.7968 - val_acc: 0.2222 - val_loss: 5.4253 - val_precision: 0.2353 - val_recall: 0.8000\n",
      "Epoch 12/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.4432 - loss: 7.8948 - precision: 0.2983 - recall: 0.8625 - val_acc: 0.2222 - val_loss: 5.7524 - val_precision: 0.2353 - val_recall: 0.8000\n",
      "Epoch 13/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.4073 - loss: 8.3824 - precision: 0.2871 - recall: 0.9323 - val_acc: 0.2778 - val_loss: 9.3673 - val_precision: 0.2778 - val_recall: 1.0000\n",
      "Epoch 14/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.3395 - loss: 9.7356 - precision: 0.2308 - recall: 0.7556 - val_acc: 0.2778 - val_loss: 9.5825 - val_precision: 0.2778 - val_recall: 1.0000\n",
      "Epoch 15/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.2727 - loss: 10.2348 - precision: 0.2117 - recall: 0.7369 - val_acc: 0.2222 - val_loss: 10.7970 - val_precision: 0.2353 - val_recall: 0.8000\n",
      "Epoch 16/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.2730 - loss: 10.3967 - precision: 0.2161 - recall: 0.7614 - val_acc: 0.2778 - val_loss: 10.8164 - val_precision: 0.2778 - val_recall: 1.0000\n",
      "Epoch 17/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.3759 - loss: 9.2482 - precision: 0.2518 - recall: 0.7285 - val_acc: 0.2778 - val_loss: 10.8444 - val_precision: 0.2778 - val_recall: 1.0000\n",
      "Epoch 18/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.3694 - loss: 9.4953 - precision: 0.2365 - recall: 0.7379 - val_acc: 0.2778 - val_loss: 10.8635 - val_precision: 0.2778 - val_recall: 1.0000\n",
      "Epoch 19/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.4073 - loss: 8.3812 - precision: 0.2679 - recall: 0.7582 - val_acc: 0.2778 - val_loss: 10.2912 - val_precision: 0.2778 - val_recall: 1.0000\n",
      "Epoch 20/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.3735 - loss: 8.7346 - precision: 0.2337 - recall: 0.8585 - val_acc: 0.2778 - val_loss: 11.5960 - val_precision: 0.2778 - val_recall: 1.0000\n",
      "Epoch 21/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.3634 - loss: 9.2329 - precision: 0.2618 - recall: 0.7735 - val_acc: 0.2778 - val_loss: 11.5900 - val_precision: 0.2778 - val_recall: 1.0000\n",
      "Epoch 22/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.3318 - loss: 9.5748 - precision: 0.2301 - recall: 0.6898 - val_acc: 0.2778 - val_loss: 10.8967 - val_precision: 0.2778 - val_recall: 1.0000\n",
      "Epoch 23/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.4026 - loss: 8.5315 - precision: 0.2934 - recall: 0.8108 - val_acc: 0.2778 - val_loss: 10.8419 - val_precision: 0.2778 - val_recall: 1.0000\n",
      "Epoch 24/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.3313 - loss: 8.9735 - precision: 0.2137 - recall: 0.7600 - val_acc: 0.2778 - val_loss: 10.8595 - val_precision: 0.2778 - val_recall: 1.0000\n",
      "Epoch 25/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.3417 - loss: 9.7851 - precision: 0.2331 - recall: 0.8591 - val_acc: 0.2778 - val_loss: 10.8498 - val_precision: 0.2778 - val_recall: 1.0000\n",
      "Epoch 26/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.3855 - loss: 8.5921 - precision: 0.2565 - recall: 0.7731 - val_acc: 0.2778 - val_loss: 10.8517 - val_precision: 0.2778 - val_recall: 1.0000\n",
      "Epoch 27/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.3178 - loss: 9.0144 - precision: 0.1944 - recall: 0.6337 - val_acc: 0.2778 - val_loss: 10.8288 - val_precision: 0.2778 - val_recall: 1.0000\n",
      "Epoch 28/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.4369 - loss: 8.0635 - precision: 0.2605 - recall: 0.8037 - val_acc: 0.2778 - val_loss: 10.8014 - val_precision: 0.2778 - val_recall: 1.0000\n",
      "Epoch 29/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.3710 - loss: 9.1183 - precision: 0.2797 - recall: 0.7703 - val_acc: 0.2778 - val_loss: 10.7992 - val_precision: 0.2778 - val_recall: 1.0000\n",
      "Epoch 30/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.4157 - loss: 8.6617 - precision: 0.2574 - recall: 0.7733 - val_acc: 0.2778 - val_loss: 10.8029 - val_precision: 0.2778 - val_recall: 1.0000\n",
      "Epoch 31/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.3287 - loss: 9.2612 - precision: 0.2241 - recall: 0.7441 - val_acc: 0.1667 - val_loss: 10.8192 - val_precision: 0.1875 - val_recall: 0.6000\n",
      "Epoch 32/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.4030 - loss: 7.9634 - precision: 0.2585 - recall: 0.8500 - val_acc: 0.1111 - val_loss: 10.8362 - val_precision: 0.1333 - val_recall: 0.4000\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T02:28:00.643248Z",
     "start_time": "2025-08-25T02:28:00.636553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create an edges array (sparse adjacency matrix) of shape [2, num_edges].\n",
    "edges = df[[\"source\", \"target\"]].to_numpy().T\n",
    "edge_weights = tf.ones(shape=edges.shape[1])\n",
    "\n",
    "node_features = tf.cast(\n",
    "    nodeset.sort_values(\"node_number\")[list(feature_names)].to_numpy(), dtype=tf.dtypes.float32\n",
    ")\n",
    "# Create graph with node features, edges, and edge_weights.\n",
    "graph_info = (node_features, edges, edge_weights)\n",
    "\n",
    "print(\"Edges shape:\", edges.shape)\n",
    "print(\"Nodes shape:\", node_features.shape)\n",
    "graph_info"
   ],
   "id": "f869046a4e5395a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edges shape: (2, 556)\n",
      "Nodes shape: (227, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(227, 6), dtype=float32, numpy=\n",
       " array([[0.000e+00, 0.000e+00, 1.800e+01, 1.000e+00, 3.607e+03, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 9.000e+00, 1.000e+00, 8.747e+03, 1.000e+00],\n",
       "        ...,\n",
       "        [0.000e+00, 0.000e+00, 2.000e+00, 0.000e+00, 0.000e+00, 3.100e+01],\n",
       "        [0.000e+00, 0.000e+00, 3.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00]],\n",
       "       dtype=float32)>,\n",
       " array([[220,  44, 191, ..., 157,  84, 180],\n",
       "        [112,   7,  56, ..., 215, 148,  60]]),\n",
       " <tf.Tensor: shape=(556,), dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T02:28:00.662265Z",
     "start_time": "2025-08-25T02:28:00.656588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GraphConvLayer(layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_units,\n",
    "        dropout_rate=0.3,\n",
    "        aggregation_type=\"mean\",\n",
    "        combination_type=\"concat\",\n",
    "        normalize=False,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.aggregation_type = aggregation_type\n",
    "        self.combination_type = combination_type\n",
    "        self.normalize = normalize\n",
    "\n",
    "        self.ffn_prepare = create_ffn(hidden_units, dropout_rate)\n",
    "        if self.combination_type == \"gated\":\n",
    "            self.update_fn = layers.GRU(\n",
    "                units=hidden_units,\n",
    "                activation=\"tanh\",\n",
    "                recurrent_activation=\"sigmoid\",\n",
    "                dropout=dropout_rate,\n",
    "                return_state=True,\n",
    "                recurrent_dropout=dropout_rate,\n",
    "            )\n",
    "        else:\n",
    "            self.update_fn = create_ffn(hidden_units, dropout_rate)\n",
    "\n",
    "    def prepare(self, node_repesentations, weights=None):\n",
    "        # node_repesentations shape is [num_edges, embedding_dim].\n",
    "        messages = self.ffn_prepare(node_repesentations)\n",
    "        if weights is not None:\n",
    "            messages = messages * tf.expand_dims(weights, -1)\n",
    "        return messages\n",
    "\n",
    "    def aggregate(self, node_indices, neighbour_messages, node_repesentations):\n",
    "\n",
    "        num_nodes = node_repesentations.shape[0]\n",
    "        if self.aggregation_type == \"sum\":\n",
    "            aggregated_message = tf.math.unsorted_segment_sum(\n",
    "                neighbour_messages, node_indices, num_segments=num_nodes\n",
    "            )\n",
    "        elif self.aggregation_type == \"mean\":\n",
    "            aggregated_message = tf.math.unsorted_segment_mean(\n",
    "                neighbour_messages, node_indices, num_segments=num_nodes\n",
    "            )\n",
    "        elif self.aggregation_type == \"max\":\n",
    "            aggregated_message = tf.math.unsorted_segment_max(\n",
    "                neighbour_messages, node_indices, num_segments=num_nodes\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid aggregation type: {self.aggregation_type}.\")\n",
    "\n",
    "        return aggregated_message\n",
    "\n",
    "    def update(self, node_repesentations, aggregated_messages):\n",
    "\n",
    "        if self.combination_type == \"gru\":\n",
    "            # Create a sequence of two elements for the GRU layer.\n",
    "            h = tf.stack([node_repesentations, aggregated_messages], axis=1)\n",
    "        elif self.combination_type == \"concat\":\n",
    "            # Concatenate the node_repesentations and aggregated_messages.\n",
    "            h = tf.concat([node_repesentations, aggregated_messages], axis=1)\n",
    "        elif self.combination_type == \"add\":\n",
    "            # Add node_repesentations and aggregated_messages.\n",
    "            h = node_repesentations + aggregated_messages\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid combination type: {self.combination_type}.\")\n",
    "\n",
    "        node_embeddings = self.update_fn(h)\n",
    "        if self.combination_type == \"gru\":\n",
    "            node_embeddings = tf.unstack(node_embeddings, axis=1)[-1]\n",
    "\n",
    "        if self.normalize:\n",
    "            node_embeddings = tf.nn.l2_normalize(node_embeddings, axis=-1)\n",
    "        return node_embeddings\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        node_repesentations, edges, edge_weights = inputs\n",
    "\n",
    "        node_indices, neighbour_indices = edges[0], edges[1]\n",
    "        neighbour_repesentations = tf.gather(node_repesentations, neighbour_indices)\n",
    "        neighbour_messages = self.prepare(neighbour_repesentations, edge_weights)\n",
    "\n",
    "        aggregated_messages = self.aggregate(\n",
    "            node_indices, neighbour_messages, node_repesentations\n",
    "        )\n",
    "\n",
    "        return self.update(node_repesentations, aggregated_messages)"
   ],
   "id": "2e89d01aca6be5ea",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T02:28:00.672209Z",
     "start_time": "2025-08-25T02:28:00.667943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GNNNodeClassifier(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        graph_info,\n",
    "        num_classes,\n",
    "        hidden_units,\n",
    "        aggregation_type=\"sum\",\n",
    "        combination_type=\"concat\",\n",
    "        dropout_rate=0.3,\n",
    "        normalize=True,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        # Unpack graph_info to three elements: node_features, edges, and edge_weight.\n",
    "        node_features, edges, edge_weights = graph_info\n",
    "        self.node_features = node_features\n",
    "        self.edges = edges\n",
    "        self.edge_weights = edge_weights\n",
    "        # Set edge_weights to ones if not provided.\n",
    "        if self.edge_weights is None:\n",
    "            self.edge_weights = tf.ones(shape=edges.shape[1])\n",
    "        # Scale edge_weights to sum to 1.\n",
    "        self.edge_weights = self.edge_weights / tf.math.reduce_sum(self.edge_weights)\n",
    "\n",
    "        # Create a process layer.\n",
    "        self.preprocess = create_ffn(hidden_units, dropout_rate, name=\"preprocess\")\n",
    "        # Create the first GraphConv layer.\n",
    "        self.conv1 = GraphConvLayer(\n",
    "            hidden_units,\n",
    "            dropout_rate,\n",
    "            aggregation_type,\n",
    "            combination_type,\n",
    "            normalize,\n",
    "            name=\"graph_conv1\",\n",
    "        )\n",
    "        # Create the second GraphConv layer.\n",
    "        self.conv2 = GraphConvLayer(\n",
    "            hidden_units,\n",
    "            dropout_rate,\n",
    "            aggregation_type,\n",
    "            combination_type,\n",
    "            normalize,\n",
    "            name=\"graph_conv2\",\n",
    "        )\n",
    "        # Create a postprocess layer.\n",
    "        self.postprocess = create_ffn(hidden_units, dropout_rate, name=\"postprocess\")\n",
    "        # Create a compute logits layer.\n",
    "        self.compute_logits = layers.Dense(units=num_classes,activation=\"softmax\", name=\"logits\")\n",
    "\n",
    "    def call(self, input_node_indices):\n",
    "        # Preprocess the node_features to produce node representations.\n",
    "        x = self.preprocess(self.node_features)\n",
    "        # Apply the first graph conv layer.\n",
    "        x1 = self.conv1((x, self.edges, self.edge_weights))\n",
    "        # Skip connection.\n",
    "        x = x1 + x\n",
    "        # Apply the second graph conv layer.\n",
    "        x2 = self.conv2((x, self.edges, self.edge_weights))\n",
    "        # Skip connection.\n",
    "        x = x2 + x\n",
    "        # Postprocess node embedding.\n",
    "        x = self.postprocess(x)\n",
    "        # Fetch node embeddings for the input node_indices.\n",
    "        node_embeddings = tf.gather(x, input_node_indices)\n",
    "        print(node_embeddings)\n",
    "        # Compute logits\n",
    "        return self.compute_logits(node_embeddings)"
   ],
   "id": "544a43bfcf72a1b",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T02:30:15.984524Z",
     "start_time": "2025-08-25T02:30:15.831146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gnn_model = GNNNodeClassifier(\n",
    "    graph_info=graph_info,\n",
    "    num_classes=num_classes,\n",
    "    hidden_units=hidden_units,\n",
    "    dropout_rate=dropout_rate,\n",
    "    name=\"gnn_model\",\n",
    ")\n",
    "\n",
    "print(\"GNN output shape:\", gnn_model(tf.constant([[1, 10, 100]], dtype=tf.int32)))\n",
    "\n",
    "gnn_model.summary()"
   ],
   "id": "b734f057e4941d05",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"GatherV2:0\", shape=(1, 3, 32), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[0.16505907 0.06232402 0.         0.         0.20010781 0.37051222\n",
      "   0.         0.         0.0317753  0.2542474  0.06731512 0.\n",
      "   0.         0.03398744 0.         0.         0.30601317 0.\n",
      "   0.01411474 0.2952409  0.         0.03910398 0.         0.\n",
      "   0.14171825 0.         0.22647277 0.1618072  0.         0.10240357\n",
      "   0.         0.05749996]\n",
      "  [1.0301948  0.25048113 0.         0.         1.3852748  1.0172032\n",
      "   0.         0.         0.         0.07357043 0.21307935 0.\n",
      "   0.         0.74481833 0.         0.         0.         0.\n",
      "   0.8963365  0.57160777 0.         1.1142474  0.7879959  0.\n",
      "   0.         0.         0.4837578  1.0602292  0.         0.14340681\n",
      "   0.6889345  0.11878217]\n",
      "  [1.0301948  0.25048113 0.         0.         1.3852748  1.0172032\n",
      "   0.         0.         0.         0.07357043 0.21307935 0.\n",
      "   0.         0.74481833 0.         0.         0.         0.\n",
      "   0.8963365  0.57160777 0.         1.1142474  0.7879959  0.\n",
      "   0.         0.         0.4837578  1.0602292  0.         0.14340681\n",
      "   0.6889345  0.11878217]]], shape=(1, 3, 32), dtype=float32)\n",
      "GNN output shape: tf.Tensor(\n",
      "[[[0.5428166  0.45718345]\n",
      "  [0.6857806  0.3142194 ]\n",
      "  [0.6857806  0.3142194 ]]], shape=(1, 3, 2), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"gnn_model\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gnn_model\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ preprocess (\u001B[38;5;33mSequential\u001B[0m)         │ (\u001B[38;5;34m227\u001B[0m, \u001B[38;5;34m32\u001B[0m)              │         \u001B[38;5;34m1,432\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ graph_conv1 (\u001B[38;5;33mGraphConvLayer\u001B[0m)    │ ?                      │         \u001B[38;5;34m5,888\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ graph_conv2 (\u001B[38;5;33mGraphConvLayer\u001B[0m)    │ ?                      │         \u001B[38;5;34m5,888\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ postprocess (\u001B[38;5;33mSequential\u001B[0m)        │ (\u001B[38;5;34m227\u001B[0m, \u001B[38;5;34m32\u001B[0m)              │         \u001B[38;5;34m2,368\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ logits (\u001B[38;5;33mDense\u001B[0m)                  │ (\u001B[38;5;34m1\u001B[0m, \u001B[38;5;34m3\u001B[0m, \u001B[38;5;34m2\u001B[0m)              │            \u001B[38;5;34m66\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ preprocess (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">227</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ graph_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GraphConvLayer</span>)    │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,888</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ graph_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GraphConvLayer</span>)    │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,888</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ postprocess (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">227</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,368</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ logits (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m15,642\u001B[0m (61.10 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,642</span> (61.10 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m14,798\u001B[0m (57.80 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,798</span> (57.80 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m844\u001B[0m (3.30 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">844</span> (3.30 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T02:31:48.069232Z",
     "start_time": "2025-08-25T02:31:48.059699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_train1 = tf.keras.utils.to_categorical(\n",
    "    y_train, num_classes=2)\n",
    "y_test1 = tf.keras.utils.to_categorical(\n",
    "    y_test, num_classes=2)"
   ],
   "id": "de04a3e8478a9318",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T02:32:05.396959Z",
     "start_time": "2025-08-25T02:32:01.880355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_train = train_data.node_number.to_numpy()\n",
    "history = run_experiment(gnn_model, x_train, y_train1)"
   ],
   "id": "3e6eca5e3fc71512",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(None, 32), dtype=float32)\n",
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(None, 32), dtype=float32)\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m14s\u001B[0m 2s/step - acc: 0.8000 - loss: 16.0877 - precision_1: 0.8000 - recall_1: 0.8000Tensor(\"gnn_model_1/GatherV2:0\", shape=(None, 32), dtype=float32)\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 35ms/step - acc: 0.7657 - loss: 54.4738 - precision_1: 0.7657 - recall_1: 0.7657 - val_acc: 0.7222 - val_loss: 38.1303 - val_precision_1: 0.7222 - val_recall_1: 0.7222\n",
      "Epoch 2/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.7549 - loss: 64.8753 - precision_1: 0.7549 - recall_1: 0.7549 - val_acc: 0.7222 - val_loss: 36.0925 - val_precision_1: 0.7222 - val_recall_1: 0.7222\n",
      "Epoch 3/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.7733 - loss: 36.3424 - precision_1: 0.7733 - recall_1: 0.7733 - val_acc: 0.7222 - val_loss: 34.1331 - val_precision_1: 0.7222 - val_recall_1: 0.7222\n",
      "Epoch 4/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - acc: 0.7770 - loss: 38.4106 - precision_1: 0.7770 - recall_1: 0.7770 - val_acc: 0.7222 - val_loss: 32.0587 - val_precision_1: 0.7222 - val_recall_1: 0.7222\n",
      "Epoch 5/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.7659 - loss: 51.4762 - precision_1: 0.7659 - recall_1: 0.7659 - val_acc: 0.7222 - val_loss: 30.1806 - val_precision_1: 0.7222 - val_recall_1: 0.7222\n",
      "Epoch 6/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.7359 - loss: 33.5988 - precision_1: 0.7359 - recall_1: 0.7359 - val_acc: 0.7222 - val_loss: 28.6146 - val_precision_1: 0.7222 - val_recall_1: 0.7222\n",
      "Epoch 7/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.8071 - loss: 26.5908 - precision_1: 0.8071 - recall_1: 0.8071 - val_acc: 0.7222 - val_loss: 27.2613 - val_precision_1: 0.7222 - val_recall_1: 0.7222\n",
      "Epoch 8/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.7585 - loss: 22.0925 - precision_1: 0.7585 - recall_1: 0.7585 - val_acc: 0.7222 - val_loss: 26.7339 - val_precision_1: 0.7222 - val_recall_1: 0.7222\n",
      "Epoch 9/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.7781 - loss: 56.3566 - precision_1: 0.7781 - recall_1: 0.7781 - val_acc: 0.7222 - val_loss: 24.4734 - val_precision_1: 0.7222 - val_recall_1: 0.7222\n",
      "Epoch 10/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.7684 - loss: 28.7696 - precision_1: 0.7684 - recall_1: 0.7684 - val_acc: 0.7222 - val_loss: 23.3406 - val_precision_1: 0.7222 - val_recall_1: 0.7222\n",
      "Epoch 11/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.7419 - loss: 23.1100 - precision_1: 0.7419 - recall_1: 0.7419 - val_acc: 0.7222 - val_loss: 22.0351 - val_precision_1: 0.7222 - val_recall_1: 0.7222\n",
      "Epoch 12/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.8062 - loss: 14.8501 - precision_1: 0.8062 - recall_1: 0.8062 - val_acc: 0.7222 - val_loss: 21.0694 - val_precision_1: 0.7222 - val_recall_1: 0.7222\n",
      "Epoch 13/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.7702 - loss: 31.5619 - precision_1: 0.7702 - recall_1: 0.7702 - val_acc: 0.7222 - val_loss: 20.0614 - val_precision_1: 0.7222 - val_recall_1: 0.7222\n",
      "Epoch 14/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.7902 - loss: 15.8416 - precision_1: 0.7902 - recall_1: 0.7902 - val_acc: 0.7222 - val_loss: 18.9628 - val_precision_1: 0.7222 - val_recall_1: 0.7222\n",
      "Epoch 15/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.7494 - loss: 26.9398 - precision_1: 0.7494 - recall_1: 0.7494 - val_acc: 0.7222 - val_loss: 17.6515 - val_precision_1: 0.7222 - val_recall_1: 0.7222\n",
      "Epoch 16/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.7093 - loss: 11.9937 - precision_1: 0.7093 - recall_1: 0.7093 - val_acc: 0.7222 - val_loss: 16.8780 - val_precision_1: 0.7222 - val_recall_1: 0.7222\n",
      "Epoch 17/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.7607 - loss: 10.5061 - precision_1: 0.7607 - recall_1: 0.7607 - val_acc: 0.7222 - val_loss: 15.6447 - val_precision_1: 0.7222 - val_recall_1: 0.7222\n",
      "Epoch 18/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.7302 - loss: 12.1881 - precision_1: 0.7302 - recall_1: 0.7302 - val_acc: 0.7222 - val_loss: 14.5100 - val_precision_1: 0.7222 - val_recall_1: 0.7222\n",
      "Epoch 19/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.7803 - loss: 23.1644 - precision_1: 0.7803 - recall_1: 0.7803 - val_acc: 0.7222 - val_loss: 13.1040 - val_precision_1: 0.7222 - val_recall_1: 0.7222\n",
      "Epoch 20/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.7176 - loss: 24.6434 - precision_1: 0.7176 - recall_1: 0.7176 - val_acc: 0.7222 - val_loss: 12.8511 - val_precision_1: 0.7222 - val_recall_1: 0.7222\n",
      "Epoch 21/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.7063 - loss: 11.1714 - precision_1: 0.7063 - recall_1: 0.7063 - val_acc: 0.7222 - val_loss: 11.9331 - val_precision_1: 0.7222 - val_recall_1: 0.7222\n",
      "Epoch 22/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.7851 - loss: 14.1318 - precision_1: 0.7851 - recall_1: 0.7851 - val_acc: 0.7222 - val_loss: 10.5367 - val_precision_1: 0.7222 - val_recall_1: 0.7222\n",
      "Epoch 23/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.7981 - loss: 8.3891 - precision_1: 0.7981 - recall_1: 0.7981 - val_acc: 0.7222 - val_loss: 9.9538 - val_precision_1: 0.7222 - val_recall_1: 0.7222\n",
      "Epoch 24/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.7965 - loss: 7.0088 - precision_1: 0.7965 - recall_1: 0.7965 - val_acc: 0.7222 - val_loss: 9.1903 - val_precision_1: 0.7222 - val_recall_1: 0.7222\n",
      "Epoch 25/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.7765 - loss: 6.9105 - precision_1: 0.7765 - recall_1: 0.7765 - val_acc: 0.7222 - val_loss: 8.2934 - val_precision_1: 0.7222 - val_recall_1: 0.7222\n",
      "Epoch 26/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.8480 - loss: 6.9721 - precision_1: 0.8480 - recall_1: 0.8480 - val_acc: 0.7222 - val_loss: 7.2835 - val_precision_1: 0.7222 - val_recall_1: 0.7222\n",
      "Epoch 27/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.8566 - loss: 4.9118 - precision_1: 0.8566 - recall_1: 0.8566 - val_acc: 0.7222 - val_loss: 6.4556 - val_precision_1: 0.7222 - val_recall_1: 0.7222\n",
      "Epoch 28/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.8507 - loss: 15.1481 - precision_1: 0.8507 - recall_1: 0.8507 - val_acc: 0.7222 - val_loss: 4.9905 - val_precision_1: 0.7222 - val_recall_1: 0.7222\n",
      "Epoch 29/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.8333 - loss: 5.3270 - precision_1: 0.8333 - recall_1: 0.8333 - val_acc: 0.7222 - val_loss: 3.9065 - val_precision_1: 0.7222 - val_recall_1: 0.7222\n",
      "Epoch 30/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - acc: 0.7910 - loss: 8.5369 - precision_1: 0.7910 - recall_1: 0.7910 - val_acc: 0.7222 - val_loss: 2.9149 - val_precision_1: 0.7222 - val_recall_1: 0.7222\n",
      "Epoch 31/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.8335 - loss: 2.1041 - precision_1: 0.8335 - recall_1: 0.8335 - val_acc: 0.7222 - val_loss: 1.8062 - val_precision_1: 0.7222 - val_recall_1: 0.7222\n",
      "Epoch 32/32\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - acc: 0.8505 - loss: 1.2673 - precision_1: 0.8505 - recall_1: 0.8505 - val_acc: 0.7222 - val_loss: 0.8162 - val_precision_1: 0.7222 - val_recall_1: 0.7222\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T02:34:39.888050Z",
     "start_time": "2025-08-25T02:34:39.836130Z"
    }
   },
   "cell_type": "code",
   "source": "gnn_model.save_weights(\"../out/saved_weights.weights.h5\")",
   "id": "62eafe34af5a59cf",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T02:43:32.932711Z",
     "start_time": "2025-08-25T02:43:32.858644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = GNNNodeClassifier(\n",
    "    graph_info=graph_info,\n",
    "    num_classes=num_classes,\n",
    "    hidden_units=hidden_units,\n",
    "    dropout_rate=dropout_rate,\n",
    "    name=\"gnn_model\",\n",
    ")\n",
    "\n",
    "model.build(input_shape=(None, graph_info[0].shape[1]))\n",
    "\n",
    "model.load_weights('../out/saved_weights.weights.h5')"
   ],
   "id": "5c485f50849866fd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruixiang/PycharmProjects/SCAR/.venv/lib/python3.9/site-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'gnn_model', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T02:43:59.643722Z",
     "start_time": "2025-08-25T02:43:59.592759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras import backend as K\n",
    "model.compile()\n",
    "x_test = test_data.node_number.to_numpy()\n",
    "_, test_accuracy, precision, recall = gnn_model.evaluate(x=x_test, y=y_test1, verbose=0)\n",
    "print(f\"Test accuracy: {round(test_accuracy * 100, 2)}%\")\n",
    "print(f\"Test precision: {(precision* 100)}%\")\n",
    "print(f\"Test recall: {(recall * 100)}%\")"
   ],
   "id": "90a92d7ca8e770b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 77.78%\n",
      "Test precision: 77.77777910232544%\n",
      "Test recall: 77.77777910232544%\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T02:49:00.508223Z",
     "start_time": "2025-08-25T02:49:00.215441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred= gnn_model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_testt = np.argmax(y_test1, axis=1)\n",
    "cm = confusion_matrix(y_testt, y_pred)\n",
    "print(cm)\n",
    "print(classification_report(y_testt,y_pred))"
   ],
   "id": "6c25594b470593c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"gnn_model_1/GatherV2:0\", shape=(32, 32), dtype=float32)\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 114ms/stepTensor(\"gnn_model_1/GatherV2:0\", shape=(None, 32), dtype=float32)\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 101ms/step\n",
      "[[42  0]\n",
      " [12  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88        42\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.78        54\n",
      "   macro avg       0.39      0.50      0.44        54\n",
      "weighted avg       0.60      0.78      0.68        54\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruixiang/PycharmProjects/SCAR/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ruixiang/PycharmProjects/SCAR/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ruixiang/PycharmProjects/SCAR/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 75
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
